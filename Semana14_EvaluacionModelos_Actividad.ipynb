{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <img src=\"https://serea2017.uniandes.edu.co/images/Logo.png\" height=\"80\" width=\"150\" align=\"Center\" /> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIIA-4203 MODELOS AVANZADOS PARA ANÁLISIS DE DATOS II\n",
    "\n",
    "\n",
    "# Evaluacion de recomendaciones\n",
    "\n",
    "## Actividad 14\n",
    "\n",
    "### Profesor: Camilo Franco (c.franco31@uniandes.edu.co)\n",
    "\n",
    "## Actividad en grupos\n",
    "### Nombres:\n",
    "\n",
    "    Arturo Guerrero            (201823464)\n",
    "    Carlos Andres Paez Rojas   (201924257)\n",
    "    \n",
    "En este cuaderno vamos a estudiar cómo evaluar las recomendaciones que obtenemos de nuestros algoritmos, enfocándonos en la *evaluación de rankings*. AL mismo tiempo, seguiremos trabajndo con los métodos de filtrado colaborativo, centrándonos en los métodos de *Baseline* o de promedios corregidos, de descomposición matricial mediante valores singulares y la factorizacion matricial no-negativa, y de vecindades por los k-vecinos más cercanos.\n",
    "\n",
    "De este modo, la evaluación de los rankings o de las listas de recomendación en base a las primeras N recomendaciones nos permiten evaluar métodos sólo a partir de su output. Sin importar si contamos con ratings explícitos o implícitos, podemos centrarnos en evaluar qué tan acertado es el *ranking* de los items, o esas recomendaciones sobre las que los usuarios toman sus decisiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Contrucción de algoritmos\n",
    "\n",
    "Podemos evaluar los sistemas de recomendación de acuerdo con el ranking que asignan sobre los items. Entonces nos interesa medir su nivel de acierto sobre un *Top-N* de items. Piense en la lista que ofrece un buscador o en un portal como youtube donde la recomendación de videos es una lista en orden de preferencia.  \n",
    "\n",
    "Puede ver el siguiente video sobre un sistema de recomendacion de este tipo en Amazon: https://www.youtube.com/watch?v=EeXBdQYs0CQ\n",
    "\n",
    "A continuación veamos algunos ejemplos sobre las recomendaciones que se pueden hacer en forma de ranking de preferencias. \n",
    "\n",
    "Finalmente, si quiere investigar sobre cómo calcular diferentes métricas como Precision@k and Recall@k, puede ver: https://surprise.readthedocs.io/en/stable/FAQ.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementemos una función `Top_N` que recibe las predicciones del sistema, el numero de recomendaciones a ofrecer y el rating mínimo a tener en cuenta.\n",
    "\n",
    "A continuación entrenemos un algoritmo *BaselineOnly* que ofrezca las 10 mejores recomendaciones para cada usuario.\n",
    "\n",
    "Primero importemos las bibliotecas y funciones que vamos a utilizar:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Reader, Dataset, BaselineOnly, accuracy, KNNBaseline\n",
    "from surprise.model_selection import LeaveOneOut, train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carguemos los datos de las películas y las preferencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pelis = pd.read_csv('C:/Users/Carlos P/Modelos Av 2/Datasets/movies_metadata.csv', low_memory=False)\n",
    "\n",
    "df = pd.read_csv('C:/Users/Carlos P/Modelos Av 2/Datasets/ratings_small.csv')\n",
    "df.drop(['timestamp'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las preferencias por usuario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2</td>\n",
       "      <td>592</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2</td>\n",
       "      <td>593</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2</td>\n",
       "      <td>616</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2</td>\n",
       "      <td>661</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating\n",
       "20       2       10     4.0\n",
       "21       2       17     5.0\n",
       "22       2       39     5.0\n",
       "23       2       47     4.0\n",
       "24       2       50     4.0\n",
       "..     ...      ...     ...\n",
       "91       2      592     5.0\n",
       "92       2      593     3.0\n",
       "93       2      616     3.0\n",
       "94       2      661     4.0\n",
       "95       2      720     4.0\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['userId'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtremos los datos para quedarnos con los usuarios y peliculas con un mínimo de entradas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos originales tienen tamaño:\t(100004, 3)\n",
      "Los nuevo datos tienen tamaño:\t(85239, 3)\n"
     ]
    }
   ],
   "source": [
    "min_p_ratings = 5\n",
    "filter_p = df['movieId'].value_counts() > min_p_ratings\n",
    "filter_p = filter_p[filter_p].index.tolist()\n",
    "\n",
    "min_u_ratings = 30\n",
    "filter_u = df['userId'].value_counts() > min_u_ratings\n",
    "filter_u = filter_u[filter_u].index.tolist()\n",
    "\n",
    "df_nuevo = df[(df['movieId'].isin(filter_p)) & (df['userId'].isin(filter_u))]\n",
    "print('Los datos originales tienen tamaño:\\t{}'.format(df.shape))\n",
    "print('Los nuevo datos tienen tamaño:\\t{}'.format(df_nuevo.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaremos los datos para trabajarlos con SurPRISE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x6cad093080>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(df_nuevo[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especifiquemos la sopciones para la implementacion del algoritmo del *BaselineOnly*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 20,\n",
    "               'reg_u': 12, \n",
    "               'reg_i': 5  \n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos entrenar el algoritmo sobre el 75% de los datos con rating observado y lo probamos sobre la muestra sobrante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "trainSet, testSet = train_test_split(data, test_size=.25, random_state=0)\n",
    "algoritmo = BaselineOnly(bsl_options=bsl_options)\n",
    "algoritmo.fit(trainSet)\n",
    "preds = algoritmo.test(testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O podemos construirlo mediante validacion cruzada. Exploremos el uso del LOOCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
    "algoritmo2 = BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "for trainSet, testSet in LOOCV.split(data):\n",
    "    # Entrenamos el modelo en entrenamiento\n",
    "    algoritmo2.fit(trainSet)\n",
    "    # Predecimos\n",
    "    predV = algoritmo2.test(testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 1\n",
    "\n",
    "Cuál es el RMSE resultante según el método de construcción del algoritmo del BaselineOnly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.874336317374522"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9499787634289079"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Con respecto a la primera predicción se logra un RMSE de **0.87**, como se observa, utilizando validación cruzada (LOOCV) se generaliza en mayor magnitud y disminuye el sesgo del error obteniendo un RMSE de **0.94**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "Encuentre un algoritmo distinto con resultados al menos tan buenos como los obtenidos por el *BaselineOnly*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### De acuerdo con los análisis realizados en la actividad anterior (semana 13), ejecutaremos inicialmente el algoritmo con mejor desempeño identificado, el cual corresponde a **KNNBaseline** con **als**, medida de similitud **pearson_baseline** y el número de vecinos de **60**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {'name': 'pearson_baseline',\n",
    "                'user_based': False  # calcula similitudes entre items\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNNBaseline: \n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "    Método de optimizacion: als\n",
      "---------------------------------------------------------------------------------\n",
      "    Inicia el entrenamiento y prueba:  2020-11-28 00:25:32.766384\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "    Termina:  2020-11-28 00:25:44.227393\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nKNNBaseline: \")\n",
    "\n",
    "bsl_options = {'method': 'als',\n",
    "                'n_epochs': 20,\n",
    "                'reg_u': 12, \n",
    "                'reg_i': 5  \n",
    "                }\n",
    "\n",
    "print(\"\\n---------------------------------------------------------------------------------\")\n",
    "print(\"    Método de optimizacion: {}\".format('als'))\n",
    "print(\"---------------------------------------------------------------------------------\")\n",
    "KNN = KNNBaseline(k=60, bsl_options=bsl_options, sim_options=sim_options)\n",
    "    \n",
    "tiempo = datetime.datetime.now()\n",
    "\n",
    "print('    Inicia el entrenamiento y prueba: ', tiempo)\n",
    "\n",
    "predKNN = KNN.fit(trainSet).test(testSet)\n",
    "    \n",
    "tiempo = datetime.datetime.now()\n",
    "print('    Termina: ', tiempo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecutamos validación cruzada (LOOCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
    "\n",
    "for trainSet, testSet in LOOCV.split(data):\n",
    "    # Entrenamos el modelo en entrenamiento\n",
    "    KNN.fit(trainSet)\n",
    "    # Predecimos\n",
    "    predKNNV = KNN.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9113508440376994"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9113508440376994"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predKNNV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se obtiene un RMSE de **0.91**, mejor a la primera predicción realizada. Con oportunidad para mejora con respecto a la validación cruzada evaluada anteriormente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluacion de rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construyamos una función para quedarnos con las N recomendaciones más atractivas para cada usuario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Top_N(preds, N, min_r):\n",
    "    topN = defaultdict(list)\n",
    "    for uid, iid, r_ui, est, _ in preds:\n",
    "        if (est >= min_r):\n",
    "            topN[int(uid)].append((int(iid), est))\n",
    "\n",
    "    for uid, ratings in topN.items():\n",
    "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        topN[int(uid)] = ratings[:N]\n",
    "\n",
    "    return topN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos qué tan bien le va a nuestro algoritmo del *BaselineOnly*. La siguiente celda toma el conjunto de entrenamiento de la implementacion del LOOCV y predice para los ratings sobrantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las predicciones que no están en entrenamiento\n",
    "X_Prueba = trainSet.build_anti_testset() #observaciones sin rating\n",
    "Preds_T = algoritmo.test(X_Prueba)\n",
    "# Calculamos las I recomendaciones para cada usuario\n",
    "topN_pred = Top_N(Preds_T, N=10, min_r=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las recomendaciones para un usuario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(969, 4.829882881081904),\n",
       " (318, 4.814097149422216),\n",
       " (3462, 4.778969585834668),\n",
       " (1221, 4.755216895401907),\n",
       " (858, 4.740759357195653),\n",
       " (3088, 4.719898252433616),\n",
       " (1172, 4.675544584905746),\n",
       " (1193, 4.66348839144212),\n",
       " (923, 4.6603933676684655),\n",
       " (1945, 4.658622202021493)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#topN_pred.keys()\n",
    "usuario=40\n",
    "topN_pred[usuario]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los titulos de las peliculas que tenemos en nuestra base original (pelis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: original_title, dtype: object)\n",
      "The Million Dollar Hotel\n",
      "Series([], Name: original_title, dtype: object)\n",
      "Series([], Name: original_title, dtype: object)\n",
      "Sleepless in Seattle\n",
      "My Darling Clementine\n",
      "Series([], Name: original_title, dtype: object)\n",
      "Series([], Name: original_title, dtype: object)\n",
      "Dawn of the Dead\n",
      "Nell\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(np.squeeze(pelis[pelis.id == str(topN_pred[usuario][i][0])]['original_title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tasa de aciertos\n",
    "\n",
    "Para evaluar nuestro recomendador, vemos la tasa de acierto. Esto es, si un usuario calificó entre sus primeras N preferencias una de las peliculas recomendadas, entonces lo consideramos un acierto.\n",
    "\n",
    "Entonces computamos la tasa de acierto para cada usuario:\n",
    "\n",
    "- Encontramos todos los items en la historia del usuario en los datos de entrenamiento.\n",
    "- Quitamos uno de esos items (algo como *Leave-One-Out cross-validation*).\n",
    "- Usamos los demás items para entrenar el recomendador y pedimos las N recomendaciones.\n",
    "- Si el item que dejamos fuera aparece en las top-N recomendaciones entonces lo consideramos un acierto. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tasa de aciertos:  0.020146520146520148\n"
     ]
    }
   ],
   "source": [
    "def TasaAcierto(topN_pred, predV):\n",
    "    aciertos = 0\n",
    "    total = 0\n",
    "\n",
    " # Para cada observacion dejada por fuera\n",
    "    for obs_out in predV:\n",
    "        userID = obs_out[0]\n",
    "        movieID_V = obs_out[1]\n",
    "        # Verficamos si se encuentra en el top-N\n",
    "        acierto = False\n",
    "        for movieID, predRating in topN_pred[int(userID)]:\n",
    "            if (int(movieID_V) == int(movieID)):\n",
    "                acierto = True\n",
    "                break\n",
    "        if (acierto) :\n",
    "            aciertos += 1\n",
    "\n",
    "        total += 1\n",
    "\n",
    "    # Calculamos la tasa de aciertos\n",
    "    return aciertos/total\n",
    "print(\"\\nTasa de aciertos: \", TasaAcierto(topN_pred, predV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deseariamos que la tasa fuera más alta. Los resultados se pueden deber a que no contamos con suficientes datos para todos los usuarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tasa de aciertos por nivel de rating\n",
    "\n",
    "También podemos discriminar por niveles del rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos por nivel de rating: \n",
      "3.5 0.020833333333333332\n",
      "4.0 0.012345679012345678\n",
      "4.5 0.022222222222222223\n",
      "5.0 0.06666666666666667\n"
     ]
    }
   ],
   "source": [
    "def TasaAcierto_R(topN_pred, predV):\n",
    "    aciertos = defaultdict(float)\n",
    "    total = defaultdict(float)\n",
    "    # Para cada rating por fuera de la muestra\n",
    "    for userID, movieID_V, ratings, est_r, _ in predV:\n",
    "        # Verficamos si se encuentra en el top-N\n",
    "        acierto = False\n",
    "        for movieID, pred_r in topN_pred[int(userID)]:\n",
    "            if (int(movieID_V) == movieID):\n",
    "                acierto = True\n",
    "                break\n",
    "        if (acierto) :\n",
    "            aciertos[ratings] += 1\n",
    "        total[ratings] += 1\n",
    "\n",
    "    # Calculamos la tasa de aciertos\n",
    "    for rating in sorted(aciertos.keys()):\n",
    "        print(rating, aciertos[rating] / total[rating])\n",
    "print(\"Tasa de aciertos por nivel de rating: \")\n",
    "TasaAcierto_R(topN_pred, predV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tasa mejora para ratings de 5, lo cual es una buena señal pues nos interesa que el sistema acierte más con las peliculas que los usuarios más prefieren.\n",
    "\n",
    "### 2.3 Tasa de acierto acumulativa\n",
    "\n",
    "Calculemos la tasa de acierto para ratings mayores que 4.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos acumulada (rating >= 4):  0.03205128205128205\n"
     ]
    }
   ],
   "source": [
    "def TasaAcierto_Acum(topN_pred, predV, umbral):\n",
    "    aciertos = 0\n",
    "    total = 0\n",
    "    # Para cada rating por fuera de la muestra\n",
    "    for userID, movieID_V, ratings, est_r, _ in predV:\n",
    "        # Nos fijamos solo en lo que los usuarios prefieren más\n",
    "        if (ratings >= umbral):\n",
    "            # Verficamos si se encuentra en el top-N\n",
    "            acierto = False\n",
    "            for movieID, pred_r in topN_pred[int(userID)]:\n",
    "                if (int(movieID_V) == movieID):\n",
    "                    acierto = True\n",
    "                    break\n",
    "            if (acierto) :\n",
    "                aciertos += 1\n",
    "            total += 1\n",
    "\n",
    "        # Calculamos la precision global\n",
    "    return aciertos/total\n",
    "print(\"Tasa de aciertos acumulada (rating >= 4): \", \n",
    "      TasaAcierto_Acum(topN_pred, predV, 4.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Tasa de aciertos promedio recíproca \n",
    "\n",
    "Otra metrica relevante es la tasa de aciertos promedio recíproca.\n",
    "\n",
    "Tomamos en cuenta donde ocurre el primer resultado relevante. Es decir, si la primera recomendación pertenece al primer lugar la tasa recíproca es de 1; si aparece en segundo lugar es de 1/2; en tercer lugar es de 1/3; etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa reciproca media de aciertos :  0.00572562358276644\n"
     ]
    }
   ],
   "source": [
    "def TasaAcierto_Recip(topN_pred, predV):\n",
    "    suma = 0\n",
    "    total = 0\n",
    "    # Para cada rating por fuera de la muestra\n",
    "    for userID, movieID_V, ratings, est_r, _ in predV:\n",
    "        # Verficamos si se encuentra en el top-N\n",
    "        aciertoRank = 0\n",
    "        rank = 0\n",
    "        for movieID, pred_r in topN_pred[int(userID)]:\n",
    "            rank = rank + 1\n",
    "            if (int(movieID_V) == movieID):\n",
    "                aciertoRank = rank\n",
    "                break\n",
    "        if (aciertoRank > 0) :\n",
    "                suma += 1.0 / aciertoRank\n",
    "\n",
    "        total += 1\n",
    "\n",
    "    return suma / total\n",
    "\n",
    "print(\"Tasa reciproca media de aciertos : \", \n",
    "      TasaAcierto_Recip(topN_pred, predV,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una tasa reciproca media de aciertos de 0.0075 nos dice que en promedio la tasa reciproca es de 1/133. De nuevo, este valor tan bajo se puede deber a que en muchos casos el algoritmo simplemente no logra recomendar las peliculas más preferidas de ciertos usuarios con poca información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "Evalúe su algoritmo propuesto en el Ejercicio 2 de acuerdo con la tasa de aciertos promedio recíproca. Analice si su algoritmo mejora las recomendaciones del BaselineOnly. El grupo que logre la mejor tasa se ganará un bono en las Actividades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las predicciones que no están en entrenamiento\n",
    "X_Prueba = trainSet.build_anti_testset() #observaciones sin rating\n",
    "Preds_T = KNN.test(X_Prueba)\n",
    "# Calculamos las I recomendaciones para cada usuario\n",
    "topN_pred = Top_N(Preds_T, N=10, min_r=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(318, 4.939594447076401),\n",
       " (969, 4.922155437358983),\n",
       " (1948, 4.91653685283992),\n",
       " (913, 4.8641493542301575),\n",
       " (1228, 4.863490135517582),\n",
       " (1217, 4.8618790289119245),\n",
       " (1212, 4.8565030146156225),\n",
       " (899, 4.844115871805349),\n",
       " (1960, 4.84096944649088),\n",
       " (858, 4.828624196973778)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#topN_pred.keys()\n",
    "usuario=40\n",
    "topN_pred[usuario]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Million Dollar Hotel\n",
      "Series([], Name: original_title, dtype: object)\n",
      "Crank\n",
      "The Thomas Crown Affair\n",
      "Series([], Name: original_title, dtype: object)\n",
      "Series([], Name: original_title, dtype: object)\n",
      "Series([], Name: original_title, dtype: object)\n",
      "Broken Blossoms\n",
      "Series([], Name: original_title, dtype: object)\n",
      "Sleepless in Seattle\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(np.squeeze(pelis[pelis.id == str(topN_pred[usuario][i][0])]['original_title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa reciproca media de aciertos :  0.004945054945054946\n"
     ]
    }
   ],
   "source": [
    "print(\"Tasa reciproca media de aciertos : \", \n",
    "      TasaAcierto_Recip(topN_pred, predKNNV,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Así, se logra una tasa de aciertos promedio reciproca de **0.0049**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### De acuerdo a lo evidenciado en clase, es importante evaluar el desempeño del algoritmo incrementando los parámetros de reug_u y reg_i de KNNBaseline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecutamos una prueba con regularización de usuario e ítem de 48 y 20 respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNNBaseline: \n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "    Método de optimizacion: als\n",
      "---------------------------------------------------------------------------------\n",
      "    Inicia el entrenamiento y prueba:  2020-11-28 00:39:51.107103\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "    Termina:  2020-11-28 00:40:02.589770\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nKNNBaseline: \")\n",
    "\n",
    "bsl_options = {'method': 'als',\n",
    "                'n_epochs': 20,\n",
    "                'reg_u': 48, \n",
    "                'reg_i': 20  \n",
    "                }\n",
    "\n",
    "print(\"\\n---------------------------------------------------------------------------------\")\n",
    "print(\"    Método de optimizacion: {}\".format('als'))\n",
    "print(\"---------------------------------------------------------------------------------\")\n",
    "KNN = KNNBaseline(k=60, bsl_options=bsl_options, sim_options=sim_options)\n",
    "    \n",
    "tiempo = datetime.datetime.now()\n",
    "\n",
    "print('    Inicia el entrenamiento y prueba: ', tiempo)\n",
    "\n",
    "predKNN = KNN.fit(trainSet).test(testSet)\n",
    "    \n",
    "tiempo = datetime.datetime.now()\n",
    "print('    Termina: ', tiempo)\n",
    "\n",
    "LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
    "\n",
    "for trainSet, testSet in LOOCV.split(data):\n",
    "    # Entrenamos el modelo en entrenamiento\n",
    "    KNN.fit(trainSet)\n",
    "    # Predecimos\n",
    "    predKNNV = KNN.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa reciproca media de aciertos :  0.007094162451305308\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos las predicciones que no están en entrenamiento\n",
    "X_Prueba = trainSet.build_anti_testset() #observaciones sin rating\n",
    "Preds_T = KNN.test(X_Prueba)\n",
    "# Calculamos las I recomendaciones para cada usuario\n",
    "topN_pred = Top_N(Preds_T, N=10, min_r=3.0)\n",
    "\n",
    "print(\"Tasa reciproca media de aciertos : \", \n",
    "      TasaAcierto_Recip(topN_pred, predKNNV,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Con ello, se logra un óptimo desempeño, pasando a una tasa de aciertos promedio reciproca de **0.0070**, obteniendo mejor tasa a la evidenciada anteriormente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
