{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <img src=\"https://serea2017.uniandes.edu.co/images/Logo.png\" height=\"80\" width=\"150\" align=\"Center\" /> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIIA-4203 MODELOS AVANZADOS PARA ANÁLISIS DE DATOS II\n",
    "\n",
    "\n",
    "# Red neuronal recurrente: LSTM bidireccional\n",
    "\n",
    "## Actividad 8\n",
    "\n",
    "### Profesor: Camilo Franco (c.franco31@uniandes.edu.co)\n",
    "\n",
    "## Actividad en grupos\n",
    "### Nombres:     \n",
    "    Arturo Guerrero            (201823464)\n",
    "    Carlos Andres Paez Rojas   (201924257)\n",
    "\n",
    "**Instrucciones:** Por favor escriba los nombres de los integrantes de su grupo. Esta actividad debe ser entregada a más tardar dentro de 8 días, con la respuesta para los ejercicios y preguntas en cada numeral.\n",
    "\n",
    "En este cuaderno vamos a implementar una red recurrente bi-direccional para la prediccion del sentimiento asociado con un comentario linguistico. Los comentarios con los que vamos a trabajar corresponden con opiniones sobre peliculas (https://ai.stanford.edu/~amaas/data/sentiment/)\n",
    "\n",
    "Finalmente tenemos un ejercicio donde podremos explorar distintos modelos de redes recurrentes (https://en.wikipedia.org/wiki/Recurrent_neural_network)\n",
    "\n",
    "Primero importemos las bibliotecas y paquetes que vamos a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import load_model, Sequential\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También definimos algunos parámetros para nuestra implementación, uno donde definimos el número máximo de términos a considerar (de todo nuestro vocabulario) y otro donde definimos la longitud máxima para un comentario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000  # Considera las 20000 palabras más populares\n",
    "maxlen = 200  # Considera las primeras 200 palabras de cada comentario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importemos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 secuencias de entrenamiento\n",
      "25000 secuencias de validación\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(\n",
    "    num_words=max_features)\n",
    "\n",
    "#x_train = x_train[0:20]#\n",
    "#y_train = y_train[0:20]#\n",
    "#x_val = x_val[0:20]#\n",
    "#y_val = y_val[0:20]#\n",
    "\n",
    "print(len(x_train), \"secuencias de entrenamiento\")\n",
    "print(len(x_val), \"secuencias de validación\")\n",
    "\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada:**\n",
    "\n",
    "25000 secuencias de entrenamiento\n",
    "\n",
    "25000 secuencias de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos en qué consiste la priemra observación de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    5,    25,   100,    43,   838,   112,    50,   670,     2,\n",
       "           9,    35,   480,   284,     5,   150,     4,   172,   112,\n",
       "         167,     2,   336,   385,    39,     4,   172,  4536,  1111,\n",
       "          17,   546,    38,    13,   447,     4,   192,    50,    16,\n",
       "           6,   147,  2025,    19,    14,    22,     4,  1920,  4613,\n",
       "         469,     4,    22,    71,    87,    12,    16,    43,   530,\n",
       "          38,    76,    15,    13,  1247,     4,    22,    17,   515,\n",
       "          17,    12,    16,   626,    18, 19193,     5,    62,   386,\n",
       "          12,     8,   316,     8,   106,     5,     4,  2223,  5244,\n",
       "          16,   480,    66,  3785,    33,     4,   130,    12,    16,\n",
       "          38,   619,     5,    25,   124,    51,    36,   135,    48,\n",
       "          25,  1415,    33,     6,    22,    12,   215,    28,    77,\n",
       "          52,     5,    14,   407,    16,    82, 10311,     8,     4,\n",
       "         107,   117,  5952,    15,   256,     4,     2,     7,  3766,\n",
       "           5,   723,    36,    71,    43,   530,   476,    26,   400,\n",
       "         317,    46,     7,     4, 12118,  1029,    13,   104,    88,\n",
       "           4,   381,    15,   297,    98,    32,  2071,    56,    26,\n",
       "         141,     6,   194,  7486,    18,     4,   226,    22,    21,\n",
       "         134,   476,    26,   480,     5,   144,    30,  5535,    18,\n",
       "          51,    36,    28,   224,    92,    25,   104,     4,   226,\n",
       "          65,    16,    38,  1334,    88,    12,    16,   283,     5,\n",
       "          16,  4472,   113,   103,    32,    15,    16,  5345,    19,\n",
       "         178,    32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reconstruir cada comentario de acuerdo con el índice de cada término:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = keras.datasets.imdb.get_word_index(path=\"imdb_word_index.json\")\n",
    "\n",
    "L = {k:(v+3) for k,v in L.items()}\n",
    "L[\"<PAD>\"] = 0\n",
    "L[\"<START>\"] = 1\n",
    "L[\"<UNK>\"] = 2\n",
    "L[\"<UNUSED>\"] = 3\n",
    "\n",
    "L_palabra = {value:key for key,value in L.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el primer comentario de entrenamiento que es positivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El comentario:  and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "Tiene un sentimiento asociado:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"El comentario: \", ' '.join(L_palabra[id] for id in x_train[0] ))\n",
    "print(\"Tiene un sentimiento asociado: \", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O un comentario negativo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El comentario:  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal measures the hair is big lots of boobs bounce men wear those cut tee shirts that show off their <UNK> sickening that men actually wore them and the music is just <UNK> trash that plays over and over again in almost every scene there is trashy music boobs and <UNK> taking away bodies and the gym still doesn't close for <UNK> all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n",
      "Tiene un sentimiento asociado:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"El comentario: \", ' '.join(L_palabra[id] for id in x_train[1] ))\n",
    "print(\"Tiene un sentimiento asociado: \", y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Red recurrente bi-direccional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación definimos la arquitectura de la red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_41 (Embedding)     (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 128)         98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,757,761\n",
      "Trainable params: 2,757,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input con secuencias de enteros con longitud variable\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "# Conseguimos la representación vectorial (embedding) de cada entero en un vector 128-dimensional\n",
    "x = layers.Embedding(max_features, 128)(inputs)\n",
    "\n",
    "# Añadimos 2 unidades LSTM bidireccionales\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "\n",
    "# Añadimos un clasificador binario en la salida\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# Gaurdamos la arquitectura del modelo\n",
    "model1 = keras.Model(inputs, outputs)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 671s 54ms/step - loss: 0.4556 - acc: 0.7798 - val_loss: 0.3436 - val_acc: 0.8591\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 626s 50ms/step - loss: 0.2225 - acc: 0.9173 - val_loss: 0.3741 - val_acc: 0.8662\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 631s 50ms/step - loss: 0.1436 - acc: 0.9504 - val_loss: 0.4245 - val_acc: 0.8510\n",
      "Desempeño (exactitud): accu_v1=0.851039999961853 , accu_v2=0.8422\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 655s 52ms/step - loss: 0.4116 - acc: 0.8220 - val_loss: 0.4260 - val_acc: 0.7939\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 605s 48ms/step - loss: 0.1981 - acc: 0.9247 - val_loss: 0.3249 - val_acc: 0.8770\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 608s 49ms/step - loss: 0.1061 - acc: 0.9643 - val_loss: 0.3429 - val_acc: 0.8884\n",
      "Desempeño (exactitud): accu_v1=0.888399999961853 , accu_v2=0.84932\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 651s 52ms/step - loss: 0.2843 - acc: 0.8863 - val_loss: 0.2152 - val_acc: 0.9173\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 611s 49ms/step - loss: 0.1187 - acc: 0.9595 - val_loss: 0.2475 - val_acc: 0.9040\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 605s 48ms/step - loss: 0.0636 - acc: 0.9794 - val_loss: 0.2887 - val_acc: 0.8842\n",
      "Desempeño (exactitud): accu_v1=0.884239999961853 , accu_v2=0.81892\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.9844 | 0.851  | 0.8422 |\n",
      "| 0.9892 | 0.8884 | 0.8493 |\n",
      "| 0.9709 | 0.8842 | 0.8189 |\n",
      "+--------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Inicializamos la tabla donde guardamos los resultados\n",
    "x = PrettyTable([\"Exac_E\", \"Exac_V\", \"Exac_P\"])\n",
    "\n",
    "# Definimos el número máximo de iteraciones (épocas de la red)\n",
    "epocas=3\n",
    "\n",
    "# Definimos los parametros del Adam\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "# Inicializamos el error \n",
    "err_p = 999\n",
    "\n",
    "for i in range(0,3,1):\n",
    "    r = i^3\n",
    "    CE_x, CV_x, CE_y, CV_y = train_test_split(x_train, y_train, test_size = 0.5, random_state = r)\n",
    "          \n",
    "    # Definimos el método de optimización con respecto a su funcion de perdida (además guardamos la exactitud para cada iteracion)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "    # Ajustamos el modelo\n",
    "    history=model.fit(x=CE_x, y=CE_y, epochs=epocas, validation_data=(CV_x, CV_y), verbose=1, shuffle=False)\n",
    "      \n",
    "    # Calculamos las metricas\n",
    "    train_metrics = model.evaluate(x=CE_x, y=CE_y, verbose=0)\n",
    "    valid_metrics = model.evaluate(x=CV_x, y=CV_y, verbose=0)\n",
    "    test_metrics = model.evaluate(x=x_val, y=y_val, verbose=0)\n",
    "    \n",
    "    # Guardamos las métricas de desempeño\n",
    "    accu_e = train_metrics[1]\n",
    "    loss_e = train_metrics[0]\n",
    "    accu_v = valid_metrics[1]\n",
    "    loss_v = valid_metrics[0]\n",
    "    accu_p = test_metrics[1]\n",
    "    loss_p = test_metrics[0]\n",
    "    \n",
    "    if (loss_p < err_p):\n",
    "        pathr =('BRNN_part='+str(r)+'.h5')\n",
    "        model.save(pathr) \n",
    "        err_p = loss_p\n",
    "        id_r = r\n",
    "    \n",
    "    # Imprimimos el desempeño para cada repetición\n",
    "    print('Desempeño (exactitud): accu_v1='+str(accu_v) +' , accu_v2='+str(accu_p))\n",
    "    \n",
    "    x.add_row([np.round(accu_e,4), np.round(accu_v,4), np.round(accu_p,4)])\n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xV9Z3v/9cnd0ISCEkIlwAJEOTmpYiACkhrp7XtqNVDf4q1ra3KQ+1tembasf15TtvT6YzT8fc7Or3oIOo8rJe0ttppe2pt1VJABQn3q9wF5GLCLQkEcvucP9YK2Yk7kEB2drLzfj4e65Hsddn7k7jMm+/3u9Z3mbsjIiLSVlK8CxARkZ5JASEiIlEpIEREJCoFhIiIRKWAEBGRqBQQIiISlQJCJE7M7DtmtrAL3+97ZvZMV72fiAJC+iwz221mtWZWE7H8JEafNcfM9kWuc/d/dve7wu3FZuZmlhKLzxc5HzoZpa+73t1fjXcRIj2RWhAibZjZo2b2q4jX/2pmr1kg18x+b2YVZnY0/L4oYt9BZvaUme0Pt//GzPoDLwPDIloqw9p0CS0Ovx4Lt1/ZtsuobSvDzErM7K9mVm1mfwbyY/7LkT5FASHyQX8PXGJmd5jZLOBO4AsezEuTBDwFjAJGArVAZLfUz4FMYBIwGPjf7n4C+ASw392zwmV/m8+cHX4dGG5/qwN1PgesJAiGHwBfOI+fVaRd6mKSvu43ZtYQ8fqb7v64md0O/BGoBr7q7vsA3P0w8Ovmnc3sh8Bfwu+HEgRBnrsfDXf5ayyKNrORwBXAR939NLDYzH4Xi8+SvksBIX3dp6ONQbj722a2k6AV8Mvm9WaWCfxv4DogN1ydbWbJwAjgSEQ4xNIw4GjYOmn2bliDSJdQF5NIFGb2ZSAd2A98K2LT3wMXAdPdPYeWriED9gKDzGxglLc817TJ0bafIOiuajYk4vsDQG44vtFs5Dk+Q6RTFBAibZjZOOCfgNuBzwHfMrPLws3ZBOMOx8xsEPDd5uPc/QDBYPTPwsHsVDNrDpBDQJ6ZDWjnYyuAJmB0xLo1wGwzGxke9+2Iz3oXKAe+b2ZpZjYTuP6CfnCRNhQQ0tf9rs19EC8BzwD/6u5r3X0b8B3g52aWDjwM9AMqgWUE4xSRPgfUA1uA94G/A3D3LcDzwE4zO2ZmwyIPcveTwA+BN8LtM9z9z8AvgHUEg9G/b/NZtwHTgSMEQfV0F/w+RM4wPTBIRESiUQtCRESiUkCIiEhUCggREYlKASEiIlEl1I1y+fn5XlxcHO8yRER6jZUrV1a6e0G0bQkVEMXFxZSXl8e7DBGRXsPM3m1vm7qYREQkKgWEiIhEpYAQEZGoFBAiIhJVTAPCzK4zs3fMbLuZ3R9le66ZvWRm68zsbTObHLHtG2a20cw2mNnzZpYRy1pFRKS1mAVEOD/+TwkeoDIRmGdmE9vs9h1gjbtfAnweeCQ8djjwNWCqu08GkoFbY1WriIh8UCxbENOA7e6+093rgDLgxjb7TARegzOzXRabWWG4LQXoFz5/N5NgXn4REekmsQyI4QQPUGm2L1wXaS1wM4CZTSN4zm+Ru78HPATsIXgwynF3/1O0DzGz+WZWbmblFRUVXfwjiIj0XBXVp/nN6vd4dNGOmLx/LG+Usyjr2s4t/iDwiJmtAdYDq4EGM8slaG2UAMeAF8zsdnd/5gNv6L4AWAAwdepUzV0uIgnrVH0jK3YfYcm2SpZsq2TzgSoAhg7I4O5ZJaQkd+2/+WMZEPto/XzcItp0E7l7FfBFADMzYFe4fBzY5e4V4bYXgasIHuQiItInuDubD1SzdHsFS7ZV8vauI5xuaCItOYnLR+XyresuYnZpAROH5pCUFO3f5BcmlgGxAig1sxLgPYJB5tsidwif3XsyHKO4C1js7lVmtgeYET4gvha4luDxiiIiCe39qlNhC6GCpdsPU1lzGoBxhVncPmMUM0vzmV4yiMy02M+UFLNPcPcGM/sK8ArBVUhPuvtGM7sn3P4YMAF42swagU3AneG25Wb2K2AV0EDQ9bQgVrWKiMRLbV0jy3cdZmnYbfTOoWoA8rPSuHpsPrNKC5g5Np8hA7r/Sv+EeuTo1KlTXZP1iUhP1tTkbDpQdaaVUL77KHWNTaSlJDGteBCzSvOZWZrPhCGx6TZqy8xWuvvUaNsSajZXEZGe6MDxWpZsq2TptkqWbq/kyIk6AMYPyeYLV41iVmkB00oGkZGaHOdKW1NAiIh0sZN1DSzfeYTF24LB5e3v1wBQkJ3OnHEFzBqXz9Vj8xmc3bMniFBAiIhcoMYmZ+P+42e6jVa+e5T6Ric9JYnpo/O4ZeoIZo3L56LCbIILNnsHBYSIyHl471gtS7dVsHhbJW9sr+TYyXoAJg7N4UszS5hdWsDlo3J7XLdRZyggREQ6oOZ0A8t2HGbJtgqWbK9kZ8UJAApz0vnohEJmlQbdRvlZ6XGutOsoIEREomhsctbtO3bm8tNVe47S0OT0S01m+uhBfHb6KGaV5lM6OKtXdRt1hgJCRCS098jJM+MIb+44zPHaesxg8rAB3D17NLNK87l8VC7pKb2326gzFBAi0mdVnarnrR3NN6lVsPvwSSCY2+jjkwqZVVrA1WPzGdQ/Lc6VxocCQkT6jIbGJtbuO3Zmsrs1e4/R2ORkpiVz5eg8vnBVMbNKCxhT0D9hu406QwEhIgnt3cMnWLytkqVht1H1qQbM4JKigdx7zRhmlebzoZG5pKXoCcxtKSBEJKEcr63nrR2VLA67jfYeqQVg+MB+/O0lQ5k5toCrx+YxMLNvdht1hgJCRHq1+sYm1uw9xpKtweWna/ceo8khKz2FK8fkcfes0cwqLaA4L1PdRp2kgBCRXsXd2VV5gqXbK1m8tZJlOw9Tc7qBJINLRwzkKx8pZVZpPpeNGEhqFz9Ap69RQIhIj3fsZB1vbA9vUttWyXvHgm6jEYP6ccNlw5hdms+Vo/MZkJka50oTiwJCRHqcuoYmVu05euby03XvHccdsjNSuGpMHvfOCQaXR+X1j3epCU0BISJx5+7sqDhxpoWwbOdhTtY1kpxkfGjEQL5+bSmzSgu4tGhAlz93WdqngBCRuDhyoo6l24PLT5dsq+TA8VMAlOT3579NKWJWaT4zxuSRk6Fuo3hRQIhItzjd0MjKd4+emcpi4/4q3CEnI4WZpfl8dWwBs0rzGTEoM96lSkgBISIx4e5se7+GxVsrWLq9kuU7j1Bb30hKkjFlVC7//aPjmDWugIuHDyC5Gx6tKZ2ngBCRLlNZc5o3wstPl26v4FDVaQBGF/TnlitGMHNs0G2Ula4/Pb2B/iuJyHk7Vd9I+e6jLNlewZKtlWw6UAXAwMxUrh6bz+zSfGaWFjB8YL84VyrnQwEhIh3m7mw5WM3SbZUs3lbB27uOcLqhidRk4/JRuXzz4xcxqzSfScPUbZQIFBAiclbvV59i6bbK4J6E7ZVUVAfdRqWDs7ht+khmlxYwrWQQ/dVtlHD0X1REWqmta+Tt3UfOXH665WA1AIP6pzFzbD6zSvOZWZrP0AHqNkp0CgiRPq6pydl8sIolYSvh7d1HqGtoIi05iStKcvnH68YzqzSfiUNzSFK3UZ+igBDpgw4eP8WSbRXhjWqVHD5RB8BFhdl8fsYoZo0rYFrxIPql9Y1Ha0p0CgiRPuBkXQPLdx1hSXj56dZDNQDkZ6Uze1wBM8cG3UaFORlxrlR6EgWESAJqanI27q9i8bYKlm6rZOW7R6lrbCI9JYlpJYOYe3kRs0oLGD8kW89IkHYpIEQSxP5jtWcuP31jeyVHT9YDMGFoDndcXcys0nyuKB5ERqq6jaRjFBAivdSJ0w0s23n4zNxGOypOADA4O50Pjx/M7NICrh6bT0F2epwrld5KASHSSzQ2ORveO86SbRUs3lbJ6j1HqW90MlKTmF6Sx7xpI5lVWsC4wix1G0mXUECI9GD7jp48c/np0u2VHK8Nuo0mD8/hzpmjmV2az5RRueo2kpiIaUCY2XXAI0AysNDdH2yzPRd4EhgDnAK+5O4bwm0DgYXAZMDDbW/Fsl6ReKs+Vc+ynUfOPDhnV2XQbTQkJ4OPTSxkZmk+M8fmk5elbiOJvZgFhJklAz8F/gbYB6wws9+6+6aI3b4DrHH3m8xsfLj/teG2R4A/uvtcM0sDNEm8JJyGxibWvXf8zOWnq/Yco7HJ6ZeazJVj8vjcjFHMHpfPmAJ1G0n3i2ULYhqw3d13AphZGXAjEBkQE4F/AXD3LWZWbGaFQC0wG7gj3FYH1MWwVpFus+fwyTOzn76xo5LqUw2YwcXDB3DPNaOZObaAKaMGkp6ibiOJr1gGxHBgb8TrfcD0NvusBW4GlprZNGAUUAQ0AhXAU2Z2KbAS+Lq7n4hhvSIxceJ0w5krjZZur+TdwycBGDYgg09OHsqscflcPSaf3P5pca5UpLVYBkS09rC3ef0g8IiZrQHWA6uBBiAVmAJ81d2Xm9kjwP3A//jAh5jNB+YDjBw5suuqF+kC+46eZN7jy9h7pJb+aUG30ZeuLmFmaT6j8/ur20h6tFgGxD5gRMTrImB/5A7uXgV8EcCC/1N2hUsmsM/dl4e7/oogID7A3RcACwCmTp3aNoBE4qY5HI6drOepO65gZmk+qclJ8S5LpMNiebauAErNrCQcZL4V+G3kDmY2MNwGcBew2N2r3P0gsNfMLgq3XUvrsQuRHi0yHJ69azofHj9Y4SC9TsxaEO7eYGZfAV4huMz1SXffaGb3hNsfAyYAT5tZI0EA3BnxFl8Fng0DZCdhS0Okp9t39CS3LljG8dogHC4pGhjvkkTOi7knTq/M1KlTvby8PN5lSB/WHA5VtfU8o3CQXsDMVrr71Gjb1OYV6SIKB0k0CgiRLrD3iMJBEo/mYhK5QHuPBAPSVbX1PHvXDC4uGhDvkkS6hFoQIhdA4SCJTC0IkfPU3K1UfUrhIIlJLQiR89AcDjWnGxQOkrDUghDppNbhMJ3JwxUOkpjUghDpBIWD9CUKCJEOUjhIX6OAEOkAhYP0RQoIkXNQOEhfpYAQOQuFg/RlCgiRdigcpK9TQIhEoXAQUUCIfMCew0E4nKhTOEjfpoAQibDncDC30om6Bp65U+EgfZsCQiSkcBBpTVNtiNDcrfQWJ+sbFQ4iIQWE9HmR4fDsXdOZNEzhIALqYpI+TuEg0j4FhPRZ7x4+oXAQOQsFhPRJ7x4+wbwFyxQOImehMQjpcyLD4bm7ZjBxWE68SxLpkRQQ0qcE3UrLqFU4iJyTupikz2gOh1MKB5EOUUBInxAZDs8qHEQ6RAEhCW93pcJB5HwoICSh7a48wbzHFQ4i50OD1JKwIsPhubtnMGGowkGkM9SCkISkcBC5cGpBSMJpHnOoa2xSOIhcALUgJKFEhsOzd01XOIhcAAWEJAyFg0jXimlAmNl1ZvaOmW03s/ujbM81s5fMbJ2ZvW1mk9tsTzaz1Wb2+1jWKb3frlbdSgoHka4Qs4Aws2Tgp8AngInAPDOb2Ga37wBr3P0S4PPAI222fx3YHKsaJTHsqgzmVmoOh/FDFA4iXSGWLYhpwHZ33+nudUAZcGObfSYCrwG4+xag2MwKAcysCPgUsDCGNUovp3AQiZ1YBsRwYG/E633hukhrgZsBzGwaMAooCrc9DHwLaDrbh5jZfDMrN7PyioqKrqhbeomgW+kthYNIjMQyICzKOm/z+kEg18zWAF8FVgMNZva3wPvuvvJcH+LuC9x9qrtPLSgouOCipXdoDof6Ruf5u2coHERiIJb3QewDRkS8LgL2R+7g7lXAFwHMzIBd4XIrcIOZfRLIAHLM7Bl3vz2G9Uov0TYcLhqSHe+SRBJSLFsQK4BSMysxszSCP/q/jdzBzAaG2wDuAha7e5W7f9vdi9y9ODzudYWDAOysqOHWBW/RoHAQibmYtSDcvcHMvgK8AiQDT7r7RjO7J9z+GDABeNrMGoFNwJ2xqkd6v50VNcx7fBkNjc5zCgeRmDP3tsMCvdfUqVO9vLw83mVIDCgcRGLDzFa6+9Ro2zQXk/R4QbfSMhqbFA4i3UkBIT1aZDg8P38G4woVDiLdRXMxSY+lcBCJLwWE9Eg7FA4icaeAkB5nR0UN8xYso8kVDiLxdM6AMLP+ZpYU8TrJzDJjW5b0VZHh8NzdCgeReOpIC+I1IDIQMoFXY1OO9GUKB5GepSMBkeHuNc0vwu/VgpAu1apbSeEg0iN0JCBOmNmU5hdmdjlQG7uSpK9pHpBuDodShYNIj9CR+yD+DnjBzJon2hsK3BK7kqQvaQ4HVziI9DjnDAh3X2Fm44GLCKbw3uLu9TGvTBLe9veD6TPcUTiI9EAduYrpy0B/d9/g7uuBLDO7L/alSSJrHQ7TFQ4iPVBHxiDudvdjzS/c/Shwd+xKkkSncBDpHToSEEnhw3wAMLNkIO0s+4u0KzIcyuYrHER6so4MUr8C/NLMHiN4ZOg9wMsxrUoS0vb3gwFpCMJh7GCFg0hP1pGA+EdgPnAvwSD1aoIrmUQ6TOEg0vucs4vJ3ZuAZcBOYCpwLbA5xnVJAtn+frXCQaQXarcFYWbjCJ4HPQ84DPwCwN0/3D2lSSIIwmE5AGXzZzB2cFacKxKRjjpbF9MWYAlwvbtvBzCzb3RLVZIQFA4ivdvZupj+G3AQ+IuZPW5m1xKMQYic07ZDQTiYKRxEeqt2A8LdX3L3W4DxwCLgG0ChmT1qZh/rpvqkF9p2qJp5jwfh8PzdCgeR3qojg9Qn3P1Zd/9boAhYA9wf88qkV1I4iCSOTj1Rzt2PuPt/uPtHYlWQ9F5BOCxTOIgkiI7cByFyTi3hYJTNn8GYAoWDSG+nZ1LLBVM4iCQmBYRckOZwSFI4iCQcBYSct60R4fC8wkEk4Sgg5LxsPVTNbQoHkYSmgJBOUziI9A0KCOmUrYeqmbdAYw4ifYECQjqsORySk4JwGK1wEEloCgjpEIWDSN+jgJBzeudgEA4pyQoHkb4kpgFhZteZ2Ttmtt3MPjB/k5nlmtlLZrbOzN42s8nh+hFm9hcz22xmG83s67GsU9r3zsFgQDol2Xj+boWDSF8Ss4Aws2Tgp8AngInAPDOb2Ga37wBr3P0S4PPAI+H6BuDv3X0CMAP4cpRjJcYUDiJ9WyxbENOA7e6+093rgDLgxjb7TAReA3D3LUCxmRW6+wF3XxWuryZ4xOnwGNYqbUSGQ9n8KxUOIn1QLANiOLA34vU+PvhHfi1wM4CZTQNGEUwpfoaZFQMfApZH+xAzm29m5WZWXlFR0SWF93XvHAzukG4Oh5L8/vEuSUTiIJYBEe3pc97m9YNArpmtAb4KrCboXgrewCwL+DXwd+5eFe1D3H2Bu09196kFBQVdU3kf1hwOqQoHkT4vltN97wNGRLwuAvZH7hD+0f8igJkZsCtcMLNUgnB41t1fjGGdEtpysIrbHl9OWnISz8+foXAQ6eNi2YJYAZSaWYmZpQG3Ar+N3MHMBobbAO4CFrt7VRgWTwCb3f3/j2GNElI4iEhbMWtBuHuDmX0FeAVIBp50941mdk+4/TFgAvC0mTUCm4A7w8OvBj4HrA+7nwC+4+5/iEmxy/8DsodA4WTILYGkvnV7iMJBRKIx97bDAr3X1KlTvby8vHMHNdbDPw+HxtPB69T+MHgCDJkcBEbhZCicCBkDur7gHiAyHMrmz6BY4SDSp5jZSnefGm2bHjmanAr/uBsqtsChjXBoQ/B1429g5X+27DdgZBgak1qCY1AJJCXHq/ILtvlAFZ9dqHAQkegUEABpmTB8SrA0c4eq/WForA+/boStr4A3BvukZgatjcJJUHhx+HUi9MuNz8/RCQoHETkXBUR7zGDA8GAZ97GW9fWnwtbGhpYWx+bfw6qnW/YZMCIMi4jWRt6YHtPaaA6H9JQknr9b4SAi0SkgOis1A4ZdFizN3KH6YBgaYXAc3ADb/tzS2kjJiNLamASZg7q1/M0Hqrjt8WVkpCYrHETkrBQQXcEMcoYGS+nftKxvOA0V70SExnp452VY/UzLPjnDI1oa4de8sZDc9f9pFA4i0hkKiFhKSYehlwRLM3eoOdS6pXFoI+x4HZrCm8iT02Hw+NYtjSEXX1BrIzIcyubPYFSewkFEzk4B0d3MgnsusofA2I+2rG+og8p3WloahzbCtj/BmojWRvbQ1i2NIc2tjdSzfuSm/VV8dqHCQUQ6RwHRU6SkBa2EIRfDpbe2rK95/4OtjZ2LoKk+2J6cBgUXtbQ2mu/f6J8PKBxE5PwpIHq6rMGQ9REY85GWdQ11cHhb69bGjtdg7XMRxxVSM3A8b+8bwI0pJcy/+QaGDTh7S0NEJJLupE4kNRXwftDSOLZ7NQe3ljOafaQ1T5CblAoF4yPGNcLWRtbg+NYtInGjO6n7iqwCyJrDpowp3PbqODLTb+P5Oy9nFAfC7qmwi2rXX2FdWctx/Qe3HgwvnAT5FwXdXiLSZykgEsym/VXctnAZmanJlM2/kpF5mcDA4B4MPtOy44nDETf7hXeLv/14y5xUSSlBSJxpaYT3b2QNDgbaRSThKSASyMb9x/nswuVtwqEd/fNg9DXB0qyxAQ5vb32X+LtvwPpftuyTmd+6pVE4Kei2SkmP3Q8mInGhgEgQnQqH9iSnBPdfDB4PF89tWX/ySOuWxqGNsGIhNJwKtlsy5I/74GSG2UPU2hDpxRQQCaA5HPqnpfD83TPOLxzOJnMQlMwKlmZNjXB4R+vpRfYsg/UvtOzTb1DEtOlhcBSMD6YrEZEeTwHRy2147zi3PxHDcGhPUjIUjAuWyTe3rK89Coc2tQ6O8qegoTbYbsnBzX2R4xqFkyBnmFobIj2MAqIXi1s4nE2/XCi+OliaNTXCkV2tQ2PvCtjw69bHRbY0CicFA+up/br/ZxARQAHRa/XIcGhPUjLkjw2WSZ9uWX/qeOvWxsENwbTp9SeD7ZYUtDYixzUKJ8GAIrU2RLqBAqIXigyHsvkzGDGoB4fD2WQMgFFXBkuzpiY4uqv1JbjvrYKNL7U+rrDNgPjgCcGDn0SkyyggepkN7wUD0lnpvTwc2pOUFDxcKW8MTLyxZf2pKnh/E63mpVrzHNTVhDtYcEzkuMaQycHDm9TaEDkvCoheJOHD4WwycmDkjGBp1tQEx3a3tDQOrocD62DTf7Xsk57zwedtFE6ENE1aKHIuCoheok+HQ3uSkmDQ6GCZcH3L+tPV8P7mlnGNQxthbRnUVYc7GAwqaT2uMWQyDByl1oZIBAVEL6Bw6KT0bBgxLViaucOxdyOmTQ+DY/PvgHDCyrTsiGeJh3eLD54QvJ9IH6SA6OEUDl3EDHKLg2X8p1rWn66Bii0t06Yf2gjrfwXlT7Tsk1vS+iFNhZNgYHHQghFJYAqIHkzh0A3Ss6BoarA0c4fje9u0NjbAlv9DS2sjCwZPbD1t+uCJwViJSIJQQPRQCoc4MoOBI4Plok+0rK87CRWbW8Y1Dm2AjS/Cyqda9hk4qvW4RuHkoAWi1ob0QgqIHkjh0EOlZcLwy4OlmTtUvde6pXFoI2x9Gbwp2Cc1E4ZNgTFzYPRHYNhlwc2DIj2cnijXwzSHQ3ZGcIe0wqGXqq8Nr6SKmDb94PpgW8ZAKJkNYz4Moz8cXFElEid6olwvsX7fcT67cBk5/VIVDr1daj8YPiVYmtVUBE/z2/EX2PkX2PzbYH1ucRAUYz4cBEe/3LiULNKWWhA9hMKhj3GHym1BUOz4C+xeEtwVbkkw7EMtgVE0TY9+lZg6WwtCAdEDRIZD2fwZFOUqHPqcxnrYV94SGO+tBG+E1P7BzLjNgVEwXjfzSZdSQPRg6/Yd4/aFyxUO0tqp47BrSUtgHNkRrM8eCqPnBIExeg5kF8avRkkIcRuDMLPrgEeAZGChuz/YZnsu8CQwBjgFfMndN3Tk2ESgcJB2ZQyACX8bLADH9rSMXWx9BdY+H6wfPKllsHvUVZrRVrpUzFoQZpYMbAX+BtgHrADmufumiH3+Dahx9++b2Xjgp+5+bUeOjaY3tSCaw2FAZjDmoHCQDmtqgoNrWwJjzzJorIPkNBgxvSUwhl6m+y/knOLVgpgGbHf3nWERZcCNQOQf+YnAvwC4+xYzKzazQmB0B47ttRQOckGSwoHsYR+CWf89uIFvz5thYCyC1/5XsPTLhZJrWgIjd1S8K5deJpYBMRzYG/F6HzC9zT5rgZuBpWY2DRgFFHXwWADMbD4wH2DkyJFdUngsrdt3jM8uXM5AhYN0lbRMGPvRYAGoPtT6ctpNvwnWDxrTEhbFM6HfwPjVLL1CLAMi2qUWbfuzHgQeMbM1wHpgNdDQwWODle4LgAUQdDGdd7XdIDIcyuZfyfCBet6yxEB2IVzy/wSLO1S80zLYveZ5WLEwuJx2+OURl9NeAcmp8a5cephYBsQ+YETE6yJgf+QO7l4FfBHAzAzYFS6Z5zq2t1E4SFyYweDxwTLjXmiog30rWgJjyUOw+EfB5IPFs1paGPmlupxWYhoQK4BSMysB3gNuBW6L3MHMBgIn3b0OuAtY7O5VZnbOY3uTtXuPcfsTCgfpAVLSgvsqiq+GjzwAtUdbX0679eVgv5zhEXd3XwNZBfGtW+IiZgHh7g1m9hXgFYJLVZ90941mdk+4/TFgAvC0mTUSDEDfebZjY1VrLDWHQ25mGs/Pn6FwkJ6lXy5MvCFYAI7uDoJix+uw5few5plg/ZCLWwJj5JXBVCKS8HSjXAwpHKRXa2qE/Wtg5+uwYxHsXQ5N9ZCcDqOubAmMwou79HLa+vp69u3bx6lTp7rsPQUyMjIoKioiNbX1WJPupI6DNXuP8TmFgySS0zXw7pst3VEVm4P1mfkw+pqWwBhQdEEfs2vXLrKzs8nLy8M0DtIl3J3Dhw9TXV1NSUnr2YM1m2s3iwyHsvkzGKZwkESQngXjPhYsAFUHgvsudob3X2z4dbA+r7T15bSdfMreqVOnKC4uVjh0ITMjLy+PioqKTh2ngOhiCgfpM3KGwmXzgsUd3t/Ucu/Fqp/D2wvAkoNLaJsDY/jlkHzuPzsKh653Pr9TBUQXWrP3GJ9buJzc/goH6WPMgsesFk6Cq74CDaeDMYvmwFj0ICz6F0jPaVbRrqAAABDISURBVH05bd4YXU7bgykgukhzOAzKSuP5uxUO0selpAcPPyqZDXwXTh5pfXf3O/8n2G/AiGBW2jEfhpI50D8vfjVHSE5O5uKLLz7z+tZbb+X+++9vd/9FixaRlpbGVVdd1R3ldRsFRBdQOIicQ+YgmHRTsLjDkZ0tg92bfgurfw4YDL0ErvhXOF0dPAsjTpMN9uvXjzVr1nR4/0WLFpGVlRU1IBoaGkhJ6Z1/antn1T3I6j1H+fwTbyscRDrKLOhayhsDV9wFjQ2wf3VLYJyuhsPbgSS+/8YJNlXUQ1JKMD1IF5g4LIfvXj/pvI4tLi7mC1/4Ar/73e+or6/nhRdeICMjg8cee4zk5GSeeeYZfvzjH/PEE08waNAgVq9ezZQpU7jvvvv48pe/TEVFBZmZmTz++OOMHz+eO+64g5ycHMrLyzl48CA/+tGPmDt3Lu7Ot771LV5++WXMjAceeIBbbrmlS37+zlBAXACFg0gXSE6BEVcEyzXfgk0bYVBREBRNVcFU5o11gEFScrikEH3Ktq5RW1vLZZdddub1t7/97TN/oPPz81m1ahU/+9nPeOihh1i4cCH33HMPWVlZ/MM//AMATzzxBFu3buXVV18lOTmZa6+9lscee4zS0lKWL1/Offfdx+uvvw7AgQMHWLp0KVu2bOGGG25g7ty5vPjii6xZs4a1a9dSWVnJFVdcwezZsxk6dGjMfuZoFBDnKTIcyubPYOgAhYNIl7Ck4IFJGQP47i1FwfxRddVBYJyuhqaGYL+UDEjPDpa0rCA4usjZuphuvvlmAC6//HJefPHFdt/jM5/5DMnJydTU1PDmm2/ymc985sy206dPn/n+05/+NElJSUycOJFDhw4BsHTpUubNm0dycjKFhYVcc801rFixghtuuKErfrwOU0Cch1V7jvIFhYNI90hJg5Q8yMwLxi8aalvC4kQlnKgALJj2PD0nCIzUzJhdHZWeng4EA9kNDQ3t7te/f38AmpqaGDhwYLuB0/x+ENzQFvk13vS4qU5SOIjEkVnwxz+rEPLGwpBLgq9ZBeBNUH0AKrfCwfXBQPiJiuCS2xjLzs6muro66racnBxKSkp44YUXgOCP/9q1a8/6frNnz+YXv/gFjY2NVFRUsHjxYqZNm9bldZ+LWhCd0BwOeVnB9BkKB5E4S0pq6WaCYMA7sjvq1PFgfXJaRHdU9jlv1ms7BnHdddfx4IMPtrv/9ddfz9y5c/mv//ovfvzjH39g+7PPPsu9997LP/3TP1FfX8+tt97KpZde2u773XTTTbz11ltceumlmBk/+tGPGDJkyFlrjgXNxdRBCgeR7rF582YmTJhw4W/kHrQe6qrhVDXU1YA3BttSMyMCo3+XXSHV00X73Woupgu0KhyQzlc4iPQeZpCaESz9C4LAqDvREhg1h4LFkoKQaB6/SMnQ3d0hBcQ5RIZD2fwrGTIgI94licj5MAsmHEzPguyhwXTmp2ugrioIjNPvBfslpba0LtKz+/SjWBUQZ6FwEElgScnQb0CwDCC4nLZ57OJ0FdQeCfY7czltTtDS6MLLaXs6BUQ7Vr57lC88qXAQ6TOaL6ftH15OW1/bEhatLqft39K6iOHltD2BAiKK5nAoyE7n+btnKBxE+hoL76tIy4TsQmhqCga5m1sY1QeCxZJbd0elpJ/7vXsRBUQbCgcR+YCkpODBR80PP2qsj+iOqoZTx4L1yWktg93pWeGUIL1X37i2q4NWvntE4SDSx82ZM4dXXnml1bqHH36Y++67r2VFcmowQ23uKObc+hXK95yEnOF88vYvc+zgbji6K7hZr+IdqNrP9x74Dg/927+dVz3xnEJcAREKwmGFwkGkj5s3bx5lZWWt1pWVlTFv3rz2D0pJh6zB/OHPixh40dXBY1ezwhvbag5B7eGgS+rwDqh5Pxjf6OA9aG+++eb5/igXrHe3f7pIZDiUzZ9BYY7CQaRHePn+4F/iXWnIxfCJ9u+Knjt3Lg888ACnT58mPT2d3bt3s3//fp577jm+8Y1vUFtby9y5c/n+97//gWOLi4spLy8nPz+fHz70CE8//TQjRhRRMGggl19cAA2nefzJ/2TBsy9SV9/A2NGj+flTj5OZW8ihyiPcc8897Ny5E4BHH32Uq666iqysLGpqatqdAnzRokV873vfIz8/nw0bNnD55ZfzzDPPdMljW/t8C+LoiTrueErhICKBvLw8pk2bxh//+EcgaD3ccsst/PCHP6S8vJx169bx17/+lXXr1rX7HitXrqSsrIzVq1fz4osvsWLVWug3EAoncvPn72XFG39l7ZI/MmHMCJ547MdwaANfm38H10y7jLXLl7CqfAWTJrV+ZkXkFOCvvvoq3/zmNzlw4AAAq1ev5uGHH2bTpk3s3LmTN954o0t+F32+BZHbP40Hb76EqcW5CgeRnuYs/9KPpeZuphtvvJGysjKefPJJfvnLX7JgwQIaGho4cOAAmzZt4pJLLol6/JIlS7jpppvIzMwEaDVN94Yt23jggQc4duwYNTU1fPyjH4Hsobz+xnKefvj7cGQHyRgD0vpDdW1wkHu7U4Dn5OQwbdo0ioqKALjsssvYvXs3M2fOvODfQ59vQQB86pKhCgcROePTn/40r732GqtWraK2tpbc3FweeughXnvtNdatW8enPvUpTp06ddb3aK+L54477uAnP/kJ69ev57vf/S6n6hshe0hwyeyQyTBoTDA1SFNDMG7hTXBwPV57LLhiKsrstJFThp9rGvLOUECIiLSRlZXFnDlz+NKXvsS8efOoqqqif//+DBgwgEOHDvHyyy+f9fjZs2fz0ksvUVtbS3V1Nb/73e/ObKuurmbo0KHU19fz7LPPnll/7bXX8uh/LICMHBqzhlCVMRwKJ595gNLsKy7lF78oo/HAeio2LmXxor8w7eKLgilDYqTPdzGJiEQzb948br75ZsrKyhg/fjwf+tCHmDRpEqNHj+bqq68+67FTpkzhlltu4bLLLmPUqFHMmjXrzLYf/OAHTJ8+nVGjRnHxxRefeY7EI488wvz583niiSdITk7m0Ucf5corrwwOyh3FTV/8Gm9tepdLP347hvOj//drDEk/yZYjO4NJCN27/K5uTfctIj1Kl033nei8KQiG5sewDhx5zkM03beISF9gbR6WFAMagxARkagUECLS4yRS13dPcT6/UwWEiPQoGRkZHD58WCHRhdydw4cPk5HRucv5NQYhIj1KUVER+/bto6KiIt6lJJSMjIwzN9N1VEwDwsyuAx4BkoGF7v5gm+0DgGeAkWEtD7n7U+G2bwB3AQ6sB77o7me/M0VEer3U1FRKSkriXYYQwy4mM0sGfgp8ApgIzDOziW12+zKwyd0vBeYA/5+ZpZnZcOBrwFR3n0wQMLfGqlYREfmgWI5BTAO2u/tOd68DyoAb2+zjQLYF96RnAUeA5nvEU4B+ZpYCZAL7Y1iriIi0EcuAGA7sjXi9L1wX6SfABII//uuBr7t7k7u/BzwE7AEOAMfd/U/RPsTM5ptZuZmVq89SRKTrxHIMIto9320vS/g4sAb4CDAG+LOZLSHoUroRKAGOAS+Y2e3u/swH3tB9AbAAwMwqzOzd86w3H6g8z2NjSXV1jurqHNXVOYlY16j2NsQyIPYBIyJeF/HBbqIvAg96cD3bdjPbBYwnKHiXu1cAmNmLwFUEA9rtcveC8y3WzMrbu908nlRX56iuzlFdndPX6oplF9MKoNTMSswsjWCQ+bdt9tkDXAtgZoXARcDOcP0MM8sMxyeuBTbHsFYREWkjZi0Id28ws68ArxB0GT3p7hvN7J5w+2PAD4D/NLP1BF1S/+julUClmf0KWEUwaL2asBtJRES6R0zvg3D3PwB/aLPusYjv9wMfa+fY7wLfjWV9bfTUAFJdnaO6Okd1dU6fqiuhpvsWEZGuo7mYREQkKgWEiIhElfABYWbXmdk7ZrbdzO6Pst3M7N/D7evMbEpHj41xXZ8N61lnZm+a2aUR23ab2XozW2NmXfoIvQ7UNcfMjoefvcbM/mdHj41xXd+MqGmDmTWa2aBwWyx/X0+a2ftmtqGd7fE6v85VV7zOr3PVFa/z61x1xev8GmFmfzGzzWa20cy+HmWf2J1j7p6wC8HVUzuA0UAasBaY2GafTwIvE1xFNQNY3tFjY1zXVUBu+P0nmusKX+8G8uP0+5oD/P58jo1lXW32vx54Pda/r/C9ZwNTgA3tbO/286uDdXX7+dXBurr9/OpIXXE8v4YCU8Lvs4Gt3fk3LNFbEB2ZD+pG4GkPLAMGmtnQDh4bs7rc/U13Pxq+XEZwo2GsXcjPHNffVxvzgOe76LPPyt0XE8wh1p54nF/nrCtO51dHfl/tievvq43uPL8OuPuq8PtqgvvB2k5ZFLNzLNEDoiPzQbW3T0eOjWVdke4k+BdCMwf+ZGYrzWx+F9XUmbquNLO1ZvaymU3q5LGxrAszywSuA34dsTpWv6+OiMf51VnddX51VHefXx0Wz/PLzIqBDwHL22yK2TmW6A8M6sh8UO3t05Fjz1eH39vMPkzwP/DMiNVXu/t+MxtMMH/VlvBfQN1R1ypglLvXmNkngd8ApR08NpZ1NbseeMPdI/81GKvfV0fE4/zqsG4+vzoiHudXZ8Tl/DKzLIJQ+jt3r2q7OcohXXKOJXoLoiPzQbW3T0eOjWVdmNklwELgRnc/3LzegxsMcff3gZcImpLdUpe7V7l7Tfj9H4BUM8vvyLGxrCvCrbRp/sfw99UR8Ti/OiQO59c5xen86oxuP7/MLJUgHJ519xej7BK7cywWAys9ZSFoIe0kmBW2eZBmUpt9PkXrAZ63O3psjOsaCWwHrmqzvj+QHfH9m8B13VjXEFpusJxGMG+Wxfv3Fe43gKAfuX93/L4iPqOY9gddu/386mBd3X5+dbCubj+/OlJXvM6v8Gd/Gnj4LPvE7BxL6C4m79h8UH8guApgO3CSYIbZdo/txrr+J5AH/MzMABo8mK2xEHgpXJcCPOfuf+zGuuYC95pZA1AL3OrB2Rjv3xfATcCf3P1ExOEx+30BmNnzBFfe5JvZPoLpYVIj6ur286uDdXX7+dXBurr9/OpgXRCH8wu4GvgcsN7M1oTrvkMQ8DE/xzTVhoiIRJXoYxAiInKeFBAiIhKVAkJERKJSQIiISFQKCBERiSqhL3MV6Wpm1gisj1hV5u4PxqsekVjSZa4inWBmNe6eFe86RLqDuphEukD4TIB/NbO3w2VsuH6Umb0WztP/mpmNDNcXmtlL4aR0a83sqnD9b8JJ3zbGaaI8kTMUECKd0y/iwTFrzOyWiG1V7j4N+AnwcLjuJwRTMV8CPAv8e7j+34G/uvulBM8haL7D9UvufjkwFfiameXF+gcSaY+6mEQ6ob0uJjPbDXzE3XeGk6sddPc8M6sEhrp7fbj+gLvnm1kFUOTup9u8z/cIpnSAYG6gj3swx79It9MgtUjX8Xa+b2+fVsxsDvBR4Ep3P2lmi4CMLqtOpJPUxSTSdW6J+PpW+P2bBFNEA3wWWBp+/xpwL4CZJZtZDsFsoUfDcBhPMDOnSNyoi0mkE6Jc5vpHd78/7GJ6imBWzSRgnrtvD58C9iSQD1QAX3T3PWZWCCwgeF5wI0FYrCJ4QM5w4B2gAPieuy+K/U8m8kEKCJEuEAbEVHevjHctIl1FXUwiIhKVWhAiIhKVWhAiIhKVAkJERKJSQIiISFQKCBERiUoBISIiUf1f+cGGO1Zod24AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['acc'])  \n",
    "plt.plot(history.history['val_acc'])  \n",
    "plt.title('Exactitud')  \n",
    "plt.ylabel('Acc')  \n",
    "plt.xlabel('Epoca')  \n",
    "plt.legend(['Entreno', 'Validacion'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(1) \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('Pérdida')  \n",
    "plt.ylabel('Pérdida')  \n",
    "plt.xlabel('Epoca')  \n",
    "plt.legend(['Entreno', 'Validación'], loc='upper right')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperamos el mejor modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_41 (Embedding)     (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 128)         98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,757,761\n",
      "Trainable params: 2,757,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# B-RNN LSTM\n",
    "model_brnn = load_model('BRNN_part='+str(id_r)+'.h5')\n",
    "\n",
    "model_brnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicamos los resultados obtenidos anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11885   615]\n",
      " [ 1196 11304]]\n",
      "Exactitud:  0.92756\n"
     ]
    }
   ],
   "source": [
    "Y_predt = model_brnn.predict(x_train)\n",
    "Y_predst = (Y_predt > 0.5)\n",
    "\n",
    "print(confusion_matrix(y_train, Y_predst))\n",
    "print(\"Exactitud: \", model_brnn.evaluate(x=x_train, y=y_train, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reportamos el desempeño del modelo con los datos de prueba (fuera de la muestra):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10827  1673]\n",
      " [ 2854  9646]]\n",
      "Exactitud:  0.81892\n"
     ]
    }
   ],
   "source": [
    "Y_predv = model_brnn.predict(x_val)\n",
    "Y_predsv = (Y_predv > 0.5)\n",
    "\n",
    "print(confusion_matrix(y_val, Y_predsv))\n",
    "print(\"Exactitud: \", model_brnn.evaluate(x=x_val, y=y_val, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.1\n",
    "\n",
    "Desarrolle un modelo de red neuronal recurrente uni-direccional para comparar los resultados obtenidos con esta red recurrente bi-direccional.\n",
    "\n",
    "Puede explorar una red recurrente simple, LSTM ó GRU, o cualquier otro tipo de red que desee explorar que contenga al menos una capa de tipo recurrente (ver por ejemplo: https://keras.io/api/layers/#recurrent-layers).\n",
    "\n",
    "Compare los resultados sobre los datos de prueba y analice el desempeño de su modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizamos la exploración con el uso de una red recurrente LSTM con 32 unidades. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En adición probamos la configuración de la red variando el algoritmo de optimización entre **SGD**, **adam** y **rmsprop**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Por otro lado, variando el método de inicialización de la primera capa recurrente entre **He**, **Xavier** y **Normal**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalmente, variamos la función de activación de dicha capa usando **relu**, **sigmoid**, **selu** y **tanh**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definiendo parámetros del algoritmo de optimización y los inicializadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01, momentum=0.001)\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "rmsprop = keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
    "\n",
    "initHe = keras.initializers.he_normal(seed=1)\n",
    "initXavier = keras.initializers.glorot_normal(seed=1)\n",
    "initNorm = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición de función de definición de arquitectura de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_1(opt, f_activation, init): \n",
    "    model_1_1 = Sequential()\n",
    "    model_1_1.add(layers.Embedding(max_features, 128, input_length=maxlen))\n",
    "    model_1_1.add(layers.LSTM(32, activation=f_activation, kernel_initializer=init, return_sequences=True))\n",
    "    model_1_1.add(layers.LSTM(32))\n",
    "    model_1_1.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model_1_1.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model_1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición de la función de entrenamiento de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_1_fit(model_1_1, string_model, err_p):\n",
    "    flg = 0\n",
    "    id_r = 0\n",
    "    # Inicializamos la tabla donde guardamos los resultados\n",
    "    x = PrettyTable([\"Exac_E\", \"Exac_V\", \"Exac_P\"])\n",
    "\n",
    "    # Definimos el número máximo de iteraciones (épocas de la red)\n",
    "    epocas=3\n",
    "\n",
    "    for i in range(0,3,1):\n",
    "        r = i^3\n",
    "        CE_x, CV_x, CE_y, CV_y = train_test_split(x_train, y_train, test_size = 0.5, random_state = r)\n",
    "\n",
    "        # Ajustamos el modelo\n",
    "        history=model_1_1.fit(x=CE_x, y=CE_y, epochs=epocas, validation_data=(CV_x, CV_y), verbose=1, shuffle=False)\n",
    "\n",
    "        # Calculamos las metricas\n",
    "        train_metrics = model_1_1.evaluate(x=CE_x, y=CE_y, verbose=0)\n",
    "        valid_metrics = model_1_1.evaluate(x=CV_x, y=CV_y, verbose=0)\n",
    "        test_metrics = model_1_1.evaluate(x=x_val, y=y_val, verbose=0)\n",
    "\n",
    "        # Guardamos las métricas de desempeño\n",
    "        accu_e = train_metrics[1]\n",
    "        loss_e = train_metrics[0]\n",
    "        accu_v = valid_metrics[1]\n",
    "        loss_v = valid_metrics[0]\n",
    "        accu_p = test_metrics[1]\n",
    "        loss_p = test_metrics[0]\n",
    "\n",
    "        if (loss_p < err_p):\n",
    "            pathr =('RNN_'+string_model+'part='+str(r)+'.h5')\n",
    "            model_1_1.save(pathr) \n",
    "            err_p = loss_p\n",
    "            id_r = r\n",
    "            flg = 1\n",
    "\n",
    "        # Imprimimos el desempeño para cada repetición\n",
    "        print('Desempeño (exactitud): accu_v1='+str(accu_v) +' , accu_v2='+str(accu_p))\n",
    "\n",
    "        x.add_row([np.round(accu_e,4), np.round(accu_v,4), np.round(accu_p,4)])\n",
    "\n",
    "    print(x)\n",
    "    \n",
    "    return flg, id_r, err_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedimiento de ciclos anidados para definir y entrenar cada red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd_relu_initHe_\n",
      "999\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 233s 19ms/step - loss: 0.6932 - acc: 0.5023 - val_loss: 0.6932 - val_acc: 0.4958\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 232s 19ms/step - loss: 0.6931 - acc: 0.5042 - val_loss: 0.6931 - val_acc: 0.4987\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 234s 19ms/step - loss: 0.6930 - acc: 0.5077 - val_loss: 0.6930 - val_acc: 0.5013\n",
      "Desempeño (exactitud): accu_v1=0.5012800000095368 , accu_v2=0.506\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 204s 16ms/step - loss: 0.6930 - acc: 0.5093 - val_loss: 0.6928 - val_acc: 0.5195\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 202s 16ms/step - loss: 0.6929 - acc: 0.5106 - val_loss: 0.6928 - val_acc: 0.5204\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 204s 16ms/step - loss: 0.6928 - acc: 0.5129 - val_loss: 0.6927 - val_acc: 0.5246\n",
      "Desempeño (exactitud): accu_v1=0.524560000038147 , accu_v2=0.52564\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 201s 16ms/step - loss: 0.6927 - acc: 0.5149 - val_loss: 0.6931 - val_acc: 0.4919\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 224s 18ms/step - loss: 0.6925 - acc: 0.5098 - val_loss: 0.6930 - val_acc: 0.4919\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 210s 17ms/step - loss: 0.6924 - acc: 0.5103 - val_loss: 0.6929 - val_acc: 0.4919\n",
      "Desempeño (exactitud): accu_v1=0.4919200000047684 , accu_v2=0.5\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.5108 | 0.5013 | 0.506  |\n",
      "| 0.5226 | 0.5246 | 0.5256 |\n",
      "| 0.5081 | 0.4919 |  0.5   |\n",
      "+--------+--------+--------+\n",
      "0.6926050445365906\n",
      "sgd_relu_initXavier_\n",
      "0.6926050445365906\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 243s 19ms/step - loss: 0.6932 - acc: 0.5008 - val_loss: 0.6932 - val_acc: 0.4967\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 215s 17ms/step - loss: 0.6932 - acc: 0.5022 - val_loss: 0.6931 - val_acc: 0.4968\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 211s 17ms/step - loss: 0.6932 - acc: 0.5038 - val_loss: 0.6931 - val_acc: 0.4968\n",
      "Desempeño (exactitud): accu_v1=0.4968000000095367 , accu_v2=0.5\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 219s 17ms/step - loss: 0.6931 - acc: 0.5056 - val_loss: 0.6931 - val_acc: 0.5052\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 215s 17ms/step - loss: 0.6931 - acc: 0.5060 - val_loss: 0.6930 - val_acc: 0.5046\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 989s 79ms/step - loss: 0.6931 - acc: 0.5076 - val_loss: 0.6930 - val_acc: 0.5049\n",
      "Desempeño (exactitud): accu_v1=0.5048800000381469 , accu_v2=0.50412\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 185s 15ms/step - loss: 0.6930 - acc: 0.5110 - val_loss: 0.6934 - val_acc: 0.4919\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 211s 17ms/step - loss: 0.6929 - acc: 0.5081 - val_loss: 0.6934 - val_acc: 0.4919\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 227s 18ms/step - loss: 0.6929 - acc: 0.5081 - val_loss: 0.6934 - val_acc: 0.4919\n",
      "Desempeño (exactitud): accu_v1=0.4919200000047684 , accu_v2=0.5\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.5033 | 0.4968 |  0.5   |\n",
      "| 0.5003 | 0.5049 | 0.5041 |\n",
      "| 0.5081 | 0.4919 |  0.5   |\n",
      "+--------+--------+--------+\n",
      "0.6926050445365906\n",
      "sgd_relu_initNorm_\n",
      "0.6926050445365906\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 201s 16ms/step - loss: 0.6933 - acc: 0.4917 - val_loss: 0.6932 - val_acc: 0.4969\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 197s 16ms/step - loss: 0.6933 - acc: 0.4927 - val_loss: 0.6932 - val_acc: 0.4969\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 203s 16ms/step - loss: 0.6932 - acc: 0.4935 - val_loss: 0.6932 - val_acc: 0.4969\n",
      "Desempeño (exactitud): accu_v1=0.49688000000953675 , accu_v2=0.5\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 207s 17ms/step - loss: 0.6932 - acc: 0.4986 - val_loss: 0.6931 - val_acc: 0.5014\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 222s 18ms/step - loss: 0.6932 - acc: 0.4997 - val_loss: 0.6931 - val_acc: 0.5014\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 234s 19ms/step - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6931 - val_acc: 0.5014\n",
      "Desempeño (exactitud): accu_v1=0.501360000038147 , accu_v2=0.5\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 226s 18ms/step - loss: 0.6931 - acc: 0.5068 - val_loss: 0.6935 - val_acc: 0.4919\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 231s 18ms/step - loss: 0.6931 - acc: 0.5081 - val_loss: 0.6936 - val_acc: 0.4919\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 213s 17ms/step - loss: 0.6931 - acc: 0.5081 - val_loss: 0.6936 - val_acc: 0.4919\n",
      "Desempeño (exactitud): accu_v1=0.4919200000047684 , accu_v2=0.5\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.5031 | 0.4969 |  0.5   |\n",
      "| 0.4986 | 0.5014 |  0.5   |\n",
      "| 0.5081 | 0.4919 |  0.5   |\n",
      "+--------+--------+--------+\n",
      "0.6926050445365906\n",
      "sgd_sigmoid_initHe_\n",
      "0.6926050445365906\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 246s 20ms/step - loss: 0.6951 - acc: 0.5012 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 222s 18ms/step - loss: 0.6934 - acc: 0.4990 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 212s 17ms/step - loss: 0.6934 - acc: 0.4993 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Desempeño (exactitud): accu_v1=0.5031200000381469 , accu_v2=0.5\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 216s 17ms/step - loss: 0.6933 - acc: 0.5041 - val_loss: 0.6931 - val_acc: 0.5014\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 208s 17ms/step - loss: 0.6933 - acc: 0.5041 - val_loss: 0.6931 - val_acc: 0.5014\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 10776s 862ms/step - loss: 0.6933 - acc: 0.5042 - val_loss: 0.6931 - val_acc: 0.5014\n",
      "Desempeño (exactitud): accu_v1=0.501360000038147 , accu_v2=0.5\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 127s 10ms/step - loss: 0.6933 - acc: 0.5042 - val_loss: 0.6936 - val_acc: 0.4919\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 152s 12ms/step - loss: 0.6932 - acc: 0.5058 - val_loss: 0.6936 - val_acc: 0.4919\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 161s 13ms/step - loss: 0.6932 - acc: 0.5057 - val_loss: 0.6936 - val_acc: 0.4919\n",
      "Desempeño (exactitud): accu_v1=0.4919200000047684 , accu_v2=0.5\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.4969 | 0.5031 |  0.5   |\n",
      "| 0.4986 | 0.5014 |  0.5   |\n",
      "| 0.5081 | 0.4919 |  0.5   |\n",
      "+--------+--------+--------+\n",
      "0.6926050445365906\n",
      "sgd_sigmoid_initXavier_\n",
      "0.6926050445365906\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 192s 15ms/step - loss: 0.6935 - acc: 0.4994 - val_loss: 0.6932 - val_acc: 0.5031\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 189s 15ms/step - loss: 0.6934 - acc: 0.5009 - val_loss: 0.6932 - val_acc: 0.5031\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 187s 15ms/step - loss: 0.6934 - acc: 0.5009 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Desempeño (exactitud): accu_v1=0.5031200000381469 , accu_v2=0.5\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 199s 16ms/step - loss: 0.6934 - acc: 0.5017 - val_loss: 0.6932 - val_acc: 0.5014\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 198s 16ms/step - loss: 0.6934 - acc: 0.5021 - val_loss: 0.6932 - val_acc: 0.5014\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 198s 16ms/step - loss: 0.6933 - acc: 0.5020 - val_loss: 0.6932 - val_acc: 0.5014\n",
      "Desempeño (exactitud): accu_v1=0.501360000038147 , accu_v2=0.5\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 201s 16ms/step - loss: 0.6934 - acc: 0.5017 - val_loss: 0.6936 - val_acc: 0.4919\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 198s 16ms/step - loss: 0.6933 - acc: 0.5050 - val_loss: 0.6936 - val_acc: 0.4919\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 204s 16ms/step - loss: 0.6933 - acc: 0.5050 - val_loss: 0.6936 - val_acc: 0.4919\n",
      "Desempeño (exactitud): accu_v1=0.4919200000047684 , accu_v2=0.5\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.4969 | 0.5031 |  0.5   |\n",
      "| 0.4986 | 0.5014 |  0.5   |\n",
      "| 0.5081 | 0.4919 |  0.5   |\n",
      "+--------+--------+--------+\n",
      "0.6926050445365906\n",
      "sgd_sigmoid_initNorm_\n",
      "0.6926050445365906\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 191s 15ms/step - loss: 0.6947 - acc: 0.5006 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 194s 16ms/step - loss: 0.6933 - acc: 0.5004 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 195s 16ms/step - loss: 0.6933 - acc: 0.5003 - val_loss: 0.6931 - val_acc: 0.5031\n",
      "Desempeño (exactitud): accu_v1=0.5031200000381469 , accu_v2=0.5\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 192s 15ms/step - loss: 0.6933 - acc: 0.5044 - val_loss: 0.6931 - val_acc: 0.5014\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 193s 15ms/step - loss: 0.6933 - acc: 0.5035 - val_loss: 0.6931 - val_acc: 0.5014\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 186s 15ms/step - loss: 0.6933 - acc: 0.5034 - val_loss: 0.6931 - val_acc: 0.5014\n",
      "Desempeño (exactitud): accu_v1=0.501360000038147 , accu_v2=0.5\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 188s 15ms/step - loss: 0.6933 - acc: 0.5031 - val_loss: 0.6936 - val_acc: 0.4919\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 190s 15ms/step - loss: 0.6932 - acc: 0.5054 - val_loss: 0.6936 - val_acc: 0.4919\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 190s 15ms/step - loss: 0.6932 - acc: 0.5055 - val_loss: 0.6936 - val_acc: 0.4919\n",
      "Desempeño (exactitud): accu_v1=0.4919200000047684 , accu_v2=0.5\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.4969 | 0.5031 |  0.5   |\n",
      "| 0.4986 | 0.5014 |  0.5   |\n",
      "| 0.5081 | 0.4919 |  0.5   |\n",
      "+--------+--------+--------+\n",
      "0.6926050445365906\n",
      "sgd_selu_initHe_\n",
      "0.6926050445365906\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 206s 16ms/step - loss: 0.6901 - acc: 0.5337 - val_loss: 0.6840 - val_acc: 0.5942\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 202s 16ms/step - loss: 0.6845 - acc: 0.5553 - val_loss: 0.6827 - val_acc: 0.5614\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 207s 17ms/step - loss: 0.6769 - acc: 0.5782 - val_loss: 0.6754 - val_acc: 0.5707\n",
      "Desempeño (exactitud): accu_v1=0.57072 , accu_v2=0.57016\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 207s 17ms/step - loss: 0.6692 - acc: 0.5985 - val_loss: 0.6489 - val_acc: 0.6422\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 210s 17ms/step - loss: 0.6605 - acc: 0.6117 - val_loss: 0.6344 - val_acc: 0.6666\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 212s 17ms/step - loss: 0.6524 - acc: 0.6274 - val_loss: 0.6340 - val_acc: 0.6520\n",
      "Desempeño (exactitud): accu_v1=0.6520000000190734 , accu_v2=0.64936\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 217s 17ms/step - loss: 0.6347 - acc: 0.6473 - val_loss: 0.6155 - val_acc: 0.6577\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 216s 17ms/step - loss: 0.6294 - acc: 0.6521 - val_loss: 0.6139 - val_acc: 0.6580\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 207s 17ms/step - loss: 0.6154 - acc: 0.6688 - val_loss: 0.5802 - val_acc: 0.7094\n",
      "Desempeño (exactitud): accu_v1=0.70936 , accu_v2=0.70992\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.5827 | 0.5707 | 0.5702 |\n",
      "| 0.6565 | 0.652  | 0.6494 |\n",
      "| 0.7173 | 0.7094 | 0.7099 |\n",
      "+--------+--------+--------+\n",
      "0.5828268080139161\n",
      "sgd_selu_initXavier_\n",
      "0.5828268080139161\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 214s 17ms/step - loss: 0.6923 - acc: 0.5172 - val_loss: 0.6908 - val_acc: 0.5582\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 212s 17ms/step - loss: 0.6903 - acc: 0.5310 - val_loss: 0.6921 - val_acc: 0.4993\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 214s 17ms/step - loss: 0.6884 - acc: 0.5359 - val_loss: 0.6899 - val_acc: 0.5580\n",
      "Desempeño (exactitud): accu_v1=0.558 , accu_v2=0.55744\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 218s 17ms/step - loss: 0.6851 - acc: 0.5595 - val_loss: 0.6763 - val_acc: 0.6000\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 209s 17ms/step - loss: 0.6814 - acc: 0.5692 - val_loss: 0.6815 - val_acc: 0.5382\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 212s 17ms/step - loss: 0.6780 - acc: 0.5748 - val_loss: 0.6565 - val_acc: 0.6485\n",
      "Desempeño (exactitud): accu_v1=0.6484799999809265 , accu_v2=0.6438\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 219s 18ms/step - loss: 0.6735 - acc: 0.5869 - val_loss: 0.6470 - val_acc: 0.6567\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 206s 17ms/step - loss: 0.6580 - acc: 0.6149 - val_loss: 0.6593 - val_acc: 0.6001\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 201s 16ms/step - loss: 0.6497 - acc: 0.6283 - val_loss: 0.6366 - val_acc: 0.6442\n",
      "Desempeño (exactitud): accu_v1=0.644159999961853 , accu_v2=0.64088\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.566  | 0.558  | 0.5574 |\n",
      "| 0.6486 | 0.6485 | 0.6438 |\n",
      "| 0.6478 | 0.6442 | 0.6409 |\n",
      "+--------+--------+--------+\n",
      "0.5828268080139161\n",
      "sgd_selu_initNorm_\n",
      "0.5828268080139161\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 212s 17ms/step - loss: 0.6934 - acc: 0.4921 - val_loss: 0.6933 - val_acc: 0.4921\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 208s 17ms/step - loss: 0.6933 - acc: 0.4960 - val_loss: 0.6932 - val_acc: 0.4963\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 215s 17ms/step - loss: 0.6932 - acc: 0.4975 - val_loss: 0.6931 - val_acc: 0.5056\n",
      "Desempeño (exactitud): accu_v1=0.5055999999809265 , accu_v2=0.503\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 220s 18ms/step - loss: 0.6932 - acc: 0.5026 - val_loss: 0.6931 - val_acc: 0.5003\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 212s 17ms/step - loss: 0.6931 - acc: 0.5034 - val_loss: 0.6930 - val_acc: 0.5018\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 213s 17ms/step - loss: 0.6930 - acc: 0.5073 - val_loss: 0.6928 - val_acc: 0.5094\n",
      "Desempeño (exactitud): accu_v1=0.509359999961853 , accu_v2=0.50796\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 212s 17ms/step - loss: 0.6928 - acc: 0.5113 - val_loss: 0.6934 - val_acc: 0.4919\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 212s 17ms/step - loss: 0.6927 - acc: 0.5137 - val_loss: 0.6928 - val_acc: 0.4924\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 213s 17ms/step - loss: 0.6923 - acc: 0.5190 - val_loss: 0.6917 - val_acc: 0.5832\n",
      "Desempeño (exactitud): accu_v1=0.583200000038147 , accu_v2=0.5742\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.5139 | 0.5056 | 0.503  |\n",
      "| 0.5102 | 0.5094 | 0.508  |\n",
      "| 0.5861 | 0.5832 | 0.5742 |\n",
      "+--------+--------+--------+\n",
      "0.5828268080139161\n",
      "sgd_tanh_initHe_\n",
      "0.5828268080139161\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 715s 57ms/step - loss: 0.6932 - acc: 0.5019 - val_loss: 0.6931 - val_acc: 0.5007\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 160s 13ms/step - loss: 0.6931 - acc: 0.5034 - val_loss: 0.6930 - val_acc: 0.5015\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 181s 14ms/step - loss: 0.6930 - acc: 0.5078 - val_loss: 0.6930 - val_acc: 0.5030\n",
      "Desempeño (exactitud): accu_v1=0.5029599999809266 , accu_v2=0.50352\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 189s 15ms/step - loss: 0.6930 - acc: 0.5100 - val_loss: 0.6927 - val_acc: 0.5281\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 196s 16ms/step - loss: 0.6929 - acc: 0.5131 - val_loss: 0.6926 - val_acc: 0.5299\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 197s 16ms/step - loss: 0.6929 - acc: 0.5151 - val_loss: 0.6926 - val_acc: 0.5330\n",
      "Desempeño (exactitud): accu_v1=0.533039999961853 , accu_v2=0.52784\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 185s 15ms/step - loss: 0.6926 - acc: 0.5204 - val_loss: 0.6930 - val_acc: 0.4920\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 188s 15ms/step - loss: 0.6924 - acc: 0.5110 - val_loss: 0.6929 - val_acc: 0.4918\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 186s 15ms/step - loss: 0.6923 - acc: 0.5122 - val_loss: 0.6928 - val_acc: 0.4920\n",
      "Desempeño (exactitud): accu_v1=0.49200000000476835 , accu_v2=0.49984\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.5103 | 0.503  | 0.5035 |\n",
      "| 0.5241 | 0.533  | 0.5278 |\n",
      "| 0.5084 | 0.492  | 0.4998 |\n",
      "+--------+--------+--------+\n",
      "0.5828268080139161\n",
      "sgd_tanh_initXavier_\n",
      "0.5828268080139161\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 192s 15ms/step - loss: 0.6931 - acc: 0.5045 - val_loss: 0.6930 - val_acc: 0.5060\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 185s 15ms/step - loss: 0.6930 - acc: 0.5073 - val_loss: 0.6930 - val_acc: 0.5068\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 185s 15ms/step - loss: 0.6929 - acc: 0.5104 - val_loss: 0.6929 - val_acc: 0.5091\n",
      "Desempeño (exactitud): accu_v1=0.5091200000095367 , accu_v2=0.51196\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 183s 15ms/step - loss: 0.6929 - acc: 0.5092 - val_loss: 0.6928 - val_acc: 0.5136\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 188s 15ms/step - loss: 0.6928 - acc: 0.5094 - val_loss: 0.6927 - val_acc: 0.5146\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 188s 15ms/step - loss: 0.6927 - acc: 0.5117 - val_loss: 0.6927 - val_acc: 0.5162\n",
      "Desempeño (exactitud): accu_v1=0.5161600000190735 , accu_v2=0.515\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 185s 15ms/step - loss: 0.6926 - acc: 0.5221 - val_loss: 0.6930 - val_acc: 0.4919\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 194s 16ms/step - loss: 0.6924 - acc: 0.5126 - val_loss: 0.6930 - val_acc: 0.4919\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 196s 16ms/step - loss: 0.6923 - acc: 0.5137 - val_loss: 0.6929 - val_acc: 0.4919\n",
      "Desempeño (exactitud): accu_v1=0.4919200000047684 , accu_v2=0.5\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.5194 | 0.5091 | 0.512  |\n",
      "| 0.5201 | 0.5162 | 0.515  |\n",
      "| 0.5081 | 0.4919 |  0.5   |\n",
      "+--------+--------+--------+\n",
      "0.5828268080139161\n",
      "sgd_tanh_initNorm_\n",
      "0.5828268080139161\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 206s 16ms/step - loss: 0.6932 - acc: 0.4962 - val_loss: 0.6931 - val_acc: 0.4969\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 197s 16ms/step - loss: 0.6932 - acc: 0.5009 - val_loss: 0.6931 - val_acc: 0.4969\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 197s 16ms/step - loss: 0.6932 - acc: 0.5020 - val_loss: 0.6931 - val_acc: 0.4969\n",
      "Desempeño (exactitud): accu_v1=0.49688000000953675 , accu_v2=0.5\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 196s 16ms/step - loss: 0.6931 - acc: 0.4995 - val_loss: 0.6931 - val_acc: 0.5049\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 203s 16ms/step - loss: 0.6931 - acc: 0.4990 - val_loss: 0.6931 - val_acc: 0.5013\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 198s 16ms/step - loss: 0.6931 - acc: 0.5009 - val_loss: 0.6931 - val_acc: 0.5013\n",
      "Desempeño (exactitud): accu_v1=0.501280000038147 , accu_v2=0.50072\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 201s 16ms/step - loss: 0.6931 - acc: 0.5066 - val_loss: 0.6934 - val_acc: 0.4919\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 205s 16ms/step - loss: 0.6930 - acc: 0.5081 - val_loss: 0.6935 - val_acc: 0.4919\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 214s 17ms/step - loss: 0.6930 - acc: 0.5081 - val_loss: 0.6935 - val_acc: 0.4919\n",
      "Desempeño (exactitud): accu_v1=0.4919200000047684 , accu_v2=0.5\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.5031 | 0.4969 |  0.5   |\n",
      "| 0.4999 | 0.5013 | 0.5007 |\n",
      "| 0.5081 | 0.4919 |  0.5   |\n",
      "+--------+--------+--------+\n",
      "0.5828268080139161\n",
      "adam_relu_initHe_\n",
      "0.5828268080139161\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 222s 18ms/step - loss: nan - acc: 0.6076 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 209s 17ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 205s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 200s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 207s 17ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 206s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 211s 17ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 209s 17ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 205s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "+--------+--------+--------+\n",
      "0.5828268080139161\n",
      "adam_relu_initXavier_\n",
      "0.5828268080139161\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 214s 17ms/step - loss: nan - acc: 0.2332 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 217s 17ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 206s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 227s 18ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 236s 19ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 213s 17ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 219s 18ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 228s 18ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 227s 18ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "+--------+--------+--------+\n",
      "0.5828268080139161\n",
      "adam_relu_initNorm_\n",
      "0.5828268080139161\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 232s 19ms/step - loss: nan - acc: 0.1588 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 222s 18ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 220s 18ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 206s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 207s 17ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 206s 17ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 204s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 206s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 205s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "+--------+--------+--------+\n",
      "0.5828268080139161\n",
      "adam_sigmoid_initHe_\n",
      "0.5828268080139161\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 213s 17ms/step - loss: 0.5883 - acc: 0.6794 - val_loss: 0.4440 - val_acc: 0.7981\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 206s 16ms/step - loss: 0.3462 - acc: 0.8553 - val_loss: 0.4486 - val_acc: 0.8046\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 203s 16ms/step - loss: 0.2624 - acc: 0.8982 - val_loss: 0.4527 - val_acc: 0.7998\n",
      "Desempeño (exactitud): accu_v1=0.7997599999809265 , accu_v2=0.79356\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 203s 16ms/step - loss: 0.2918 - acc: 0.8854 - val_loss: 0.2920 - val_acc: 0.8867\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 208s 17ms/step - loss: 0.2059 - acc: 0.9250 - val_loss: 0.2948 - val_acc: 0.8841\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 203s 16ms/step - loss: 0.1479 - acc: 0.9489 - val_loss: 0.2965 - val_acc: 0.8908\n",
      "Desempeño (exactitud): accu_v1=0.8907999999809265 , accu_v2=0.8404\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 203s 16ms/step - loss: 0.2010 - acc: 0.9276 - val_loss: 0.2291 - val_acc: 0.9119\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 201s 16ms/step - loss: 0.1331 - acc: 0.9564 - val_loss: 0.2026 - val_acc: 0.9291\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 199s 16ms/step - loss: 0.0872 - acc: 0.9729 - val_loss: 0.2234 - val_acc: 0.9285\n",
      "Desempeño (exactitud): accu_v1=0.92848 , accu_v2=0.84212\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.9352 | 0.7998 | 0.7936 |\n",
      "| 0.9746 | 0.8908 | 0.8404 |\n",
      "| 0.9861 | 0.9285 | 0.8421 |\n",
      "+--------+--------+--------+\n",
      "0.43466512516975403\n",
      "adam_sigmoid_initXavier_\n",
      "0.43466512516975403\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 213s 17ms/step - loss: 0.5468 - acc: 0.7091 - val_loss: 0.4039 - val_acc: 0.8287\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 200s 16ms/step - loss: 0.3097 - acc: 0.8746 - val_loss: 0.3862 - val_acc: 0.8417\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 207s 17ms/step - loss: 0.2309 - acc: 0.9108 - val_loss: 0.3919 - val_acc: 0.8475\n",
      "Desempeño (exactitud): accu_v1=0.8475199999809265 , accu_v2=0.83964\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 205s 16ms/step - loss: 0.2674 - acc: 0.8961 - val_loss: 0.2525 - val_acc: 0.9005\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 204s 16ms/step - loss: 0.1930 - acc: 0.9271 - val_loss: 0.2570 - val_acc: 0.9011\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 201s 16ms/step - loss: 0.1428 - acc: 0.9514 - val_loss: 0.2805 - val_acc: 0.8955\n",
      "Desempeño (exactitud): accu_v1=0.895519999961853 , accu_v2=0.84444\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 202s 16ms/step - loss: 0.1909 - acc: 0.9304 - val_loss: 0.1910 - val_acc: 0.9302\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 202s 16ms/step - loss: 0.1367 - acc: 0.9534 - val_loss: 0.2049 - val_acc: 0.9250\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 200s 16ms/step - loss: 0.0950 - acc: 0.9708 - val_loss: 0.2494 - val_acc: 0.9187\n",
      "Desempeño (exactitud): accu_v1=0.91872 , accu_v2=0.84772\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.9477 | 0.8475 | 0.8396 |\n",
      "| 0.9702 | 0.8955 | 0.8444 |\n",
      "| 0.9786 | 0.9187 | 0.8477 |\n",
      "+--------+--------+--------+\n",
      "0.4108415650653839\n",
      "adam_sigmoid_initNorm_\n",
      "0.4108415650653839\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 216s 17ms/step - loss: 0.5648 - acc: 0.6959 - val_loss: 0.4208 - val_acc: 0.8182\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 206s 16ms/step - loss: 0.3212 - acc: 0.8670 - val_loss: 0.4178 - val_acc: 0.8100\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 203s 16ms/step - loss: 0.2179 - acc: 0.9157 - val_loss: 0.3837 - val_acc: 0.8499\n",
      "Desempeño (exactitud): accu_v1=0.8499200000381469 , accu_v2=0.8418\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 202s 16ms/step - loss: 0.2626 - acc: 0.8973 - val_loss: 0.2472 - val_acc: 0.9028\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 199s 16ms/step - loss: 0.1877 - acc: 0.9333 - val_loss: 0.2870 - val_acc: 0.8938\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 202s 16ms/step - loss: 0.1260 - acc: 0.9582 - val_loss: 0.2906 - val_acc: 0.9002\n",
      "Desempeño (exactitud): accu_v1=0.9001599999809266 , accu_v2=0.84944\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 206s 16ms/step - loss: 0.1796 - acc: 0.9354 - val_loss: 0.1727 - val_acc: 0.9418\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 201s 16ms/step - loss: 0.1093 - acc: 0.9650 - val_loss: 0.2120 - val_acc: 0.9274\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 202s 16ms/step - loss: 0.0667 - acc: 0.9798 - val_loss: 0.2241 - val_acc: 0.9311\n",
      "Desempeño (exactitud): accu_v1=0.93112 , accu_v2=0.84464\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.9549 | 0.8499 | 0.8418 |\n",
      "| 0.9788 | 0.9002 | 0.8494 |\n",
      "| 0.9873 | 0.9311 | 0.8446 |\n",
      "+--------+--------+--------+\n",
      "0.40727037920475007\n",
      "adam_selu_initHe_\n",
      "0.40727037920475007\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 218s 17ms/step - loss: 0.5362 - acc: 0.7297 - val_loss: 0.4423 - val_acc: 0.7990\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 211s 17ms/step - loss: 0.3056 - acc: 0.8731 - val_loss: 0.3851 - val_acc: 0.8395\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 212s 17ms/step - loss: 0.2028 - acc: 0.9258 - val_loss: 0.4085 - val_acc: 0.8374\n",
      "Desempeño (exactitud): accu_v1=0.8374399999809266 , accu_v2=0.82252\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 206s 16ms/step - loss: 0.2557 - acc: 0.8985 - val_loss: 0.2555 - val_acc: 0.9018\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 211s 17ms/step - loss: 0.1668 - acc: 0.9430 - val_loss: 0.2545 - val_acc: 0.9055\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 208s 17ms/step - loss: 0.1244 - acc: 0.9583 - val_loss: 0.4835 - val_acc: 0.7781\n",
      "Desempeño (exactitud): accu_v1=0.7780799999618531 , accu_v2=0.72804\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 209s 17ms/step - loss: 0.2080 - acc: 0.9225 - val_loss: 0.1865 - val_acc: 0.9337\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 208s 17ms/step - loss: 0.1289 - acc: 0.9567 - val_loss: 0.1873 - val_acc: 0.9342\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 209s 17ms/step - loss: 0.1111 - acc: 0.9637 - val_loss: 0.2156 - val_acc: 0.9266\n",
      "Desempeño (exactitud): accu_v1=0.9266399999809265 , accu_v2=0.84984\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.9318 | 0.8374 | 0.8225 |\n",
      "| 0.8138 | 0.7781 | 0.728  |\n",
      "| 0.9828 | 0.9266 | 0.8498 |\n",
      "+--------+--------+--------+\n",
      "0.40727037920475007\n",
      "adam_selu_initXavier_\n",
      "0.40727037920475007\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 227s 18ms/step - loss: 0.6803 - acc: 0.5574 - val_loss: 0.6460 - val_acc: 0.5863\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 216s 17ms/step - loss: 0.5896 - acc: 0.6287 - val_loss: 0.6547 - val_acc: 0.5875\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 215s 17ms/step - loss: 0.5381 - acc: 0.6607 - val_loss: 0.7022 - val_acc: 0.5926\n",
      "Desempeño (exactitud): accu_v1=0.5926400000095368 , accu_v2=0.594\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 216s 17ms/step - loss: 0.5851 - acc: 0.6350 - val_loss: 0.5915 - val_acc: 0.6343\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 215s 17ms/step - loss: 0.5457 - acc: 0.6560 - val_loss: 0.5804 - val_acc: 0.6438\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 218s 17ms/step - loss: 0.5293 - acc: 0.6707 - val_loss: 0.6257 - val_acc: 0.6149\n",
      "Desempeño (exactitud): accu_v1=0.6148800000190735 , accu_v2=0.57476\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 215s 17ms/step - loss: 0.5544 - acc: 0.6582 - val_loss: 0.5454 - val_acc: 0.6578\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 215s 17ms/step - loss: 0.5301 - acc: 0.6727 - val_loss: 0.5538 - val_acc: 0.6563\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 217s 17ms/step - loss: 0.5118 - acc: 0.6801 - val_loss: 0.5601 - val_acc: 0.6546\n",
      "Desempeño (exactitud): accu_v1=0.6545600000190734 , accu_v2=0.60704\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.6804 | 0.5926 | 0.594  |\n",
      "| 0.6587 | 0.6149 | 0.5748 |\n",
      "| 0.6882 | 0.6546 | 0.607  |\n",
      "+--------+--------+--------+\n",
      "0.40727037920475007\n",
      "adam_selu_initNorm_\n",
      "0.40727037920475007\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 223s 18ms/step - loss: 0.5050 - acc: 0.7511 - val_loss: 0.4254 - val_acc: 0.8183\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 211s 17ms/step - loss: 0.2731 - acc: 0.8936 - val_loss: 0.4409 - val_acc: 0.8139\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 213s 17ms/step - loss: 0.1835 - acc: 0.9322 - val_loss: 0.5499 - val_acc: 0.7222\n",
      "Desempeño (exactitud): accu_v1=0.7222399999809265 , accu_v2=0.711\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 215s 17ms/step - loss: 0.2613 - acc: 0.8950 - val_loss: 0.2653 - val_acc: 0.8966\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 213s 17ms/step - loss: 0.1588 - acc: 0.9450 - val_loss: 0.2831 - val_acc: 0.9010\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 216s 17ms/step - loss: 0.0952 - acc: 0.9707 - val_loss: 0.3063 - val_acc: 0.9034\n",
      "Desempeño (exactitud): accu_v1=0.9034399999809265 , accu_v2=0.85204\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 214s 17ms/step - loss: 0.1849 - acc: 0.9330 - val_loss: 0.1662 - val_acc: 0.9439\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 215s 17ms/step - loss: 0.1019 - acc: 0.9692 - val_loss: 0.1727 - val_acc: 0.9425\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 215s 17ms/step - loss: 0.0672 - acc: 0.9819 - val_loss: 0.1966 - val_acc: 0.9388\n",
      "Desempeño (exactitud): accu_v1=0.9388 , accu_v2=0.85328\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.8113 | 0.7222 | 0.711  |\n",
      "| 0.9863 | 0.9034 | 0.852  |\n",
      "| 0.991  | 0.9388 | 0.8533 |\n",
      "+--------+--------+--------+\n",
      "0.40727037920475007\n",
      "adam_tanh_initHe_\n",
      "0.40727037920475007\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 212s 17ms/step - loss: 0.5526 - acc: 0.7258 - val_loss: 0.4692 - val_acc: 0.7866\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 198s 16ms/step - loss: 0.3299 - acc: 0.8673 - val_loss: 0.3754 - val_acc: 0.8411\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 196s 16ms/step - loss: 0.2343 - acc: 0.9114 - val_loss: 0.3942 - val_acc: 0.8421\n",
      "Desempeño (exactitud): accu_v1=0.842079999961853 , accu_v2=0.83772\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 197s 16ms/step - loss: 0.2611 - acc: 0.8999 - val_loss: 0.2530 - val_acc: 0.9027\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 198s 16ms/step - loss: 0.1623 - acc: 0.9451 - val_loss: 0.2729 - val_acc: 0.9006\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 198s 16ms/step - loss: 0.1064 - acc: 0.9662 - val_loss: 0.3363 - val_acc: 0.8850\n",
      "Desempeño (exactitud): accu_v1=0.8849599999809266 , accu_v2=0.83788\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 197s 16ms/step - loss: 0.1961 - acc: 0.9290 - val_loss: 0.1950 - val_acc: 0.9302\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 195s 16ms/step - loss: 0.1217 - acc: 0.9603 - val_loss: 0.2102 - val_acc: 0.9272\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 197s 16ms/step - loss: 0.0757 - acc: 0.9774 - val_loss: 0.2344 - val_acc: 0.9283\n",
      "Desempeño (exactitud): accu_v1=0.9283199999809265 , accu_v2=0.84648\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.9566 | 0.8421 | 0.8377 |\n",
      "| 0.9688 | 0.885  | 0.8379 |\n",
      "| 0.9908 | 0.9283 | 0.8465 |\n",
      "+--------+--------+--------+\n",
      "0.4055254195022583\n",
      "adam_tanh_initXavier_\n",
      "0.4055254195022583\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 204s 16ms/step - loss: 0.5133 - acc: 0.7478 - val_loss: 0.4180 - val_acc: 0.8285\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 200s 16ms/step - loss: 0.2535 - acc: 0.8997 - val_loss: 0.3661 - val_acc: 0.8478\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 196s 16ms/step - loss: 0.1507 - acc: 0.9454 - val_loss: 0.3998 - val_acc: 0.8511\n",
      "Desempeño (exactitud): accu_v1=0.8511199999809265 , accu_v2=0.84152\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 194s 16ms/step - loss: 0.2313 - acc: 0.9158 - val_loss: 0.2212 - val_acc: 0.9170\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 195s 16ms/step - loss: 0.1276 - acc: 0.9564 - val_loss: 0.2579 - val_acc: 0.9127\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 193s 15ms/step - loss: 0.0686 - acc: 0.9794 - val_loss: 0.2998 - val_acc: 0.9118\n",
      "Desempeño (exactitud): accu_v1=0.911759999961853 , accu_v2=0.85728\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 193s 15ms/step - loss: 0.1558 - acc: 0.9482 - val_loss: 0.1516 - val_acc: 0.9481\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 202s 16ms/step - loss: 0.0783 - acc: 0.9762 - val_loss: 0.1616 - val_acc: 0.9476\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 190s 15ms/step - loss: 0.0404 - acc: 0.9886 - val_loss: 0.2046 - val_acc: 0.9415\n",
      "Desempeño (exactitud): accu_v1=0.9415199999809265 , accu_v2=0.85808\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.9767 | 0.8511 | 0.8415 |\n",
      "| 0.9913 | 0.9118 | 0.8573 |\n",
      "| 0.9944 | 0.9415 | 0.8581 |\n",
      "+--------+--------+--------+\n",
      "0.4055254195022583\n",
      "adam_tanh_initNorm_\n",
      "0.4055254195022583\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 200s 16ms/step - loss: 0.5065 - acc: 0.7522 - val_loss: 0.6443 - val_acc: 0.6298\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 186s 15ms/step - loss: 0.2774 - acc: 0.8882 - val_loss: 0.3473 - val_acc: 0.8508\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 188s 15ms/step - loss: 0.1569 - acc: 0.9447 - val_loss: 0.4231 - val_acc: 0.8399\n",
      "Desempeño (exactitud): accu_v1=0.8399199999809265 , accu_v2=0.83004\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 185s 15ms/step - loss: 0.2574 - acc: 0.9009 - val_loss: 0.2295 - val_acc: 0.9170\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 186s 15ms/step - loss: 0.1734 - acc: 0.9389 - val_loss: 0.2448 - val_acc: 0.9142\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 186s 15ms/step - loss: 0.1067 - acc: 0.9653 - val_loss: 0.2752 - val_acc: 0.9126\n",
      "Desempeño (exactitud): accu_v1=0.9125599999809265 , accu_v2=0.85736\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 185s 15ms/step - loss: 0.1607 - acc: 0.9465 - val_loss: 0.1608 - val_acc: 0.9453\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 187s 15ms/step - loss: 0.0924 - acc: 0.9715 - val_loss: 0.1684 - val_acc: 0.9438\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 187s 15ms/step - loss: 0.0532 - acc: 0.9860 - val_loss: 0.1967 - val_acc: 0.9422\n",
      "Desempeño (exactitud): accu_v1=0.9422399999809266 , accu_v2=0.85664\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.961  | 0.8399 |  0.83  |\n",
      "| 0.9826 | 0.9126 | 0.8574 |\n",
      "| 0.9923 | 0.9422 | 0.8566 |\n",
      "+--------+--------+--------+\n",
      "0.4055254195022583\n",
      "rmsprop_relu_initHe_\n",
      "0.4055254195022583\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 190s 15ms/step - loss: nan - acc: 0.2607 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 182s 15ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 180s 14ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 185s 15ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 188s 15ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 194s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 191s 15ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 192s 15ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 191s 15ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "+--------+--------+--------+\n",
      "0.4055254195022583\n",
      "rmsprop_relu_initXavier_\n",
      "0.4055254195022583\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 208s 17ms/step - loss: 0.4717 - acc: 0.7685 - val_loss: 0.3982 - val_acc: 0.8354\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 194s 16ms/step - loss: nan - acc: 0.2747 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 193s 15ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 193s 15ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 194s 15ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 197s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 195s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 197s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 193s 15ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "+--------+--------+--------+\n",
      "0.4055254195022583\n",
      "rmsprop_relu_initNorm_\n",
      "0.4055254195022583\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 208s 17ms/step - loss: nan - acc: 0.3899 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 198s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 198s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 195s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 198s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 199s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 198s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 197s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 200s 16ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "+--------+--------+--------+\n",
      "0.4055254195022583\n",
      "rmsprop_sigmoid_initHe_\n",
      "0.4055254195022583\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 214s 17ms/step - loss: 0.5777 - acc: 0.6756 - val_loss: 0.4795 - val_acc: 0.7666\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 201s 16ms/step - loss: 0.3658 - acc: 0.8452 - val_loss: 0.3611 - val_acc: 0.8313\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 203s 16ms/step - loss: 0.2788 - acc: 0.8875 - val_loss: 0.4299 - val_acc: 0.8335\n",
      "Desempeño (exactitud): accu_v1=0.83352 , accu_v2=0.82676\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 201s 16ms/step - loss: 0.2971 - acc: 0.8788 - val_loss: 0.2952 - val_acc: 0.8876\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 208s 17ms/step - loss: 0.2397 - acc: 0.9066 - val_loss: 0.3236 - val_acc: 0.8796\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 205s 16ms/step - loss: 0.2017 - acc: 0.9268 - val_loss: 0.4019 - val_acc: 0.8438\n",
      "Desempeño (exactitud): accu_v1=0.8438400000190734 , accu_v2=0.81344\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 208s 17ms/step - loss: 0.2430 - acc: 0.9085 - val_loss: 0.3479 - val_acc: 0.8427\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 221s 18ms/step - loss: 0.2008 - acc: 0.9251 - val_loss: 0.3170 - val_acc: 0.8749\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 206s 16ms/step - loss: 0.1734 - acc: 0.9362 - val_loss: 0.2383 - val_acc: 0.9110\n",
      "Desempeño (exactitud): accu_v1=0.9109599999809265 , accu_v2=0.86036\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.8933 | 0.8335 | 0.8268 |\n",
      "| 0.8965 | 0.8438 | 0.8134 |\n",
      "| 0.9602 | 0.911  | 0.8604 |\n",
      "+--------+--------+--------+\n",
      "0.3595839903020859\n",
      "rmsprop_sigmoid_initXavier_\n",
      "0.3595839903020859\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 275s 22ms/step - loss: 0.5901 - acc: 0.6614 - val_loss: 0.6107 - val_acc: 0.6871\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 282s 23ms/step - loss: 0.3749 - acc: 0.8426 - val_loss: 0.3592 - val_acc: 0.8444\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 296s 24ms/step - loss: 0.2773 - acc: 0.8895 - val_loss: 0.3645 - val_acc: 0.8672\n",
      "Desempeño (exactitud): accu_v1=0.8671999999809266 , accu_v2=0.85216\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 299s 24ms/step - loss: 0.3001 - acc: 0.8832 - val_loss: 0.3429 - val_acc: 0.8521\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 293s 23ms/step - loss: 0.2489 - acc: 0.9068 - val_loss: 0.3090 - val_acc: 0.8687\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 303s 24ms/step - loss: 0.2060 - acc: 0.9246 - val_loss: 0.3056 - val_acc: 0.8726\n",
      "Desempeño (exactitud): accu_v1=0.8725600000190735 , accu_v2=0.84468\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 305s 24ms/step - loss: 0.2415 - acc: 0.9069 - val_loss: 0.2194 - val_acc: 0.9166\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 295s 24ms/step - loss: 0.1997 - acc: 0.9258 - val_loss: 0.2420 - val_acc: 0.9091\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 307s 25ms/step - loss: 0.1775 - acc: 0.9357 - val_loss: 0.2689 - val_acc: 0.9012\n",
      "Desempeño (exactitud): accu_v1=0.9011999999618531 , accu_v2=0.85636\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.9244 | 0.8672 | 0.8522 |\n",
      "| 0.9363 | 0.8726 | 0.8447 |\n",
      "| 0.9533 | 0.9012 | 0.8564 |\n",
      "+--------+--------+--------+\n",
      "0.3595839903020859\n",
      "rmsprop_sigmoid_initNorm_\n",
      "0.3595839903020859\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 326s 26ms/step - loss: 0.5740 - acc: 0.6802 - val_loss: 0.4912 - val_acc: 0.7647\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 309s 25ms/step - loss: 0.3583 - acc: 0.8501 - val_loss: 0.3448 - val_acc: 0.8557\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 286s 23ms/step - loss: 0.2758 - acc: 0.8923 - val_loss: 0.3449 - val_acc: 0.8596\n",
      "Desempeño (exactitud): accu_v1=0.859600000038147 , accu_v2=0.85532\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 260s 21ms/step - loss: 0.2904 - acc: 0.8865 - val_loss: 0.2689 - val_acc: 0.8953\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 239s 19ms/step - loss: 0.2374 - acc: 0.9117 - val_loss: 0.3059 - val_acc: 0.8770\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 247s 20ms/step - loss: 0.2007 - acc: 0.9262 - val_loss: 0.3631 - val_acc: 0.8568\n",
      "Desempeño (exactitud): accu_v1=0.8568000000381469 , accu_v2=0.83052\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 248s 20ms/step - loss: 0.2397 - acc: 0.9067 - val_loss: 0.2513 - val_acc: 0.9019\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 245s 20ms/step - loss: 0.2008 - acc: 0.9268 - val_loss: 0.2352 - val_acc: 0.9130\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 242s 19ms/step - loss: 0.1792 - acc: 0.9329 - val_loss: 0.2378 - val_acc: 0.9103\n",
      "Desempeño (exactitud): accu_v1=0.9103199999809265 , accu_v2=0.86104\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.9314 | 0.8596 | 0.8553 |\n",
      "| 0.9152 | 0.8568 | 0.8305 |\n",
      "| 0.9603 | 0.9103 | 0.861  |\n",
      "+--------+--------+--------+\n",
      "0.3595839903020859\n",
      "rmsprop_selu_initHe_\n",
      "0.3595839903020859\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 267s 21ms/step - loss: 0.4581 - acc: 0.7903 - val_loss: 0.3442 - val_acc: 0.8576\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 237s 19ms/step - loss: 0.3957 - acc: 0.8102 - val_loss: 0.4728 - val_acc: 0.7787\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 234s 19ms/step - loss: nan - acc: 0.7058 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 236s 19ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 231s 18ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 233s 19ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 234s 19ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 232s 19ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 241s 19ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "+--------+--------+--------+\n",
      "0.3595839903020859\n",
      "rmsprop_selu_initXavier_\n",
      "0.3595839903020859\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 265s 21ms/step - loss: 0.4647 - acc: 0.7826 - val_loss: 0.3985 - val_acc: 0.8251\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 250s 20ms/step - loss: 0.4516 - acc: 0.7885 - val_loss: 0.5268 - val_acc: 0.7440\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 235s 19ms/step - loss: 0.4505 - acc: 0.7658 - val_loss: 0.4234 - val_acc: 0.8206\n",
      "Desempeño (exactitud): accu_v1=0.820640000038147 , accu_v2=0.80864\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 244s 19ms/step - loss: 0.3591 - acc: 0.8475 - val_loss: 0.3971 - val_acc: 0.8237\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 239s 19ms/step - loss: 0.2744 - acc: 0.8908 - val_loss: 0.2918 - val_acc: 0.8818\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 233s 19ms/step - loss: nan - acc: 0.3455 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 229s 18ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 236s 19ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 240s 19ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.8828 | 0.8206 | 0.8086 |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "+--------+--------+--------+\n",
      "0.3595839903020859\n",
      "rmsprop_selu_initNorm_\n",
      "0.3595839903020859\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 270s 22ms/step - loss: 0.4734 - acc: 0.7752 - val_loss: 0.4498 - val_acc: 0.7934\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 257s 21ms/step - loss: 0.4556 - acc: 0.7716 - val_loss: 0.4964 - val_acc: 0.7670\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 257s 21ms/step - loss: 0.3657 - acc: 0.8436 - val_loss: 0.5106 - val_acc: 0.7803\n",
      "Desempeño (exactitud): accu_v1=0.7803200000190735 , accu_v2=0.77768\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 239s 19ms/step - loss: 0.3555 - acc: 0.8518 - val_loss: 0.4545 - val_acc: 0.8322\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 237s 19ms/step - loss: 0.5127 - acc: 0.7520 - val_loss: 0.6062 - val_acc: 0.6608\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 242s 19ms/step - loss: 0.3120 - acc: 0.8714 - val_loss: 0.3021 - val_acc: 0.8752\n",
      "Desempeño (exactitud): accu_v1=0.8752 , accu_v2=0.84744\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 238s 19ms/step - loss: 0.2636 - acc: 0.8911 - val_loss: 0.2559 - val_acc: 0.8965\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 231s 18ms/step - loss: 0.2100 - acc: 0.9195 - val_loss: 0.2526 - val_acc: 0.9009\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 233s 19ms/step - loss: 0.1827 - acc: 0.9340 - val_loss: 0.6156 - val_acc: 0.8374\n",
      "Desempeño (exactitud): accu_v1=0.8373599999809265 , accu_v2=0.78964\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.8321 | 0.7803 | 0.7777 |\n",
      "| 0.9106 | 0.8752 | 0.8474 |\n",
      "| 0.8807 | 0.8374 | 0.7896 |\n",
      "+--------+--------+--------+\n",
      "0.35939048040390015\n",
      "rmsprop_tanh_initHe_\n",
      "0.35939048040390015\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 236s 19ms/step - loss: 0.4304 - acc: 0.8036 - val_loss: 0.3549 - val_acc: 0.8462\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 225s 18ms/step - loss: 0.2546 - acc: 0.9054 - val_loss: 0.2976 - val_acc: 0.8773\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 229s 18ms/step - loss: 0.1867 - acc: 0.9339 - val_loss: 0.3954 - val_acc: 0.8620\n",
      "Desempeño (exactitud): accu_v1=0.8619999999809265 , accu_v2=0.84472\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 224s 18ms/step - loss: 0.2412 - acc: 0.9060 - val_loss: 0.2493 - val_acc: 0.9029\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 224s 18ms/step - loss: 0.1699 - acc: 0.9361 - val_loss: 0.2684 - val_acc: 0.8982\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 224s 18ms/step - loss: 0.1248 - acc: 0.9558 - val_loss: 0.2971 - val_acc: 0.8874\n",
      "Desempeño (exactitud): accu_v1=0.8874399999618531 , accu_v2=0.85588\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 225s 18ms/step - loss: 0.1977 - acc: 0.9289 - val_loss: 0.1781 - val_acc: 0.9359\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 226s 18ms/step - loss: 0.1424 - acc: 0.9508 - val_loss: 0.1936 - val_acc: 0.9312\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 225s 18ms/step - loss: 0.1133 - acc: 0.9608 - val_loss: 0.2484 - val_acc: 0.9074\n",
      "Desempeño (exactitud): accu_v1=0.9073599999809265 , accu_v2=0.85468\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.9586 | 0.862  | 0.8447 |\n",
      "| 0.9678 | 0.8874 | 0.8559 |\n",
      "| 0.9684 | 0.9074 | 0.8547 |\n",
      "+--------+--------+--------+\n",
      "0.35939048040390015\n",
      "rmsprop_tanh_initXavier_\n",
      "0.35939048040390015\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 248s 20ms/step - loss: 0.4398 - acc: 0.7954 - val_loss: 0.3796 - val_acc: 0.8350\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 238s 19ms/step - loss: 0.2530 - acc: 0.9036 - val_loss: 0.2975 - val_acc: 0.8770\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 248s 20ms/step - loss: 0.1940 - acc: 0.9302 - val_loss: 0.3510 - val_acc: 0.8702\n",
      "Desempeño (exactitud): accu_v1=0.8701599999809265 , accu_v2=0.84928\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 239s 19ms/step - loss: 0.2477 - acc: 0.9050 - val_loss: 0.2394 - val_acc: 0.9104\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 249s 20ms/step - loss: 0.1705 - acc: 0.9365 - val_loss: 0.2710 - val_acc: 0.8989\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 242s 19ms/step - loss: 0.1256 - acc: 0.9564 - val_loss: 0.2917 - val_acc: 0.8786\n",
      "Desempeño (exactitud): accu_v1=0.8785600000381469 , accu_v2=0.84084\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 241s 19ms/step - loss: 0.1882 - acc: 0.9320 - val_loss: 0.1796 - val_acc: 0.9352\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 240s 19ms/step - loss: 0.1410 - acc: 0.9500 - val_loss: 0.1975 - val_acc: 0.9303\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 244s 20ms/step - loss: 0.1026 - acc: 0.9640 - val_loss: 0.2410 - val_acc: 0.9250\n",
      "Desempeño (exactitud): accu_v1=0.9249599999809265 , accu_v2=0.86292\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.9643 | 0.8702 | 0.8493 |\n",
      "| 0.9623 | 0.8786 | 0.8408 |\n",
      "| 0.9814 | 0.925  | 0.8629 |\n",
      "+--------+--------+--------+\n",
      "0.35939048040390015\n",
      "rmsprop_tanh_initNorm_\n",
      "0.35939048040390015\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 253s 20ms/step - loss: 0.4357 - acc: 0.7995 - val_loss: 0.3690 - val_acc: 0.8417\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 237s 19ms/step - loss: 0.2554 - acc: 0.9051 - val_loss: 0.3462 - val_acc: 0.8528\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 239s 19ms/step - loss: 0.1958 - acc: 0.9323 - val_loss: 0.3537 - val_acc: 0.8694\n",
      "Desempeño (exactitud): accu_v1=0.8694399999618531 , accu_v2=0.85208\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 237s 19ms/step - loss: 0.2401 - acc: 0.9052 - val_loss: 0.2773 - val_acc: 0.8894\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 234s 19ms/step - loss: 0.1775 - acc: 0.9335 - val_loss: 0.3992 - val_acc: 0.8716\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 235s 19ms/step - loss: 0.1390 - acc: 0.9509 - val_loss: 0.3521 - val_acc: 0.8875\n",
      "Desempeño (exactitud): accu_v1=0.887519999961853 , accu_v2=0.85432\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 234s 19ms/step - loss: 0.1975 - acc: 0.9266 - val_loss: 0.2216 - val_acc: 0.9088\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 237s 19ms/step - loss: 0.1526 - acc: 0.9450 - val_loss: 0.2305 - val_acc: 0.9152\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 242s 19ms/step - loss: 0.1165 - acc: 0.9604 - val_loss: 0.2393 - val_acc: 0.9236\n",
      "Desempeño (exactitud): accu_v1=0.923599999961853 , accu_v2=0.86564\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.9623 | 0.8694 | 0.8521 |\n",
      "| 0.9582 | 0.8875 | 0.8543 |\n",
      "| 0.9794 | 0.9236 | 0.8656 |\n",
      "+--------+--------+--------+\n",
      "0.35939048040390015\n"
     ]
    }
   ],
   "source": [
    "opt_s = 'sgd', 'adam', 'rmsprop'\n",
    "init_s = 'initHe', 'initXavier', 'initNorm'\n",
    "opt = sgd, adam, rmsprop\n",
    "f_activation='relu', 'sigmoid', 'selu', 'tanh'\n",
    "init = initHe, initXavier, initNorm \n",
    "ii = 0\n",
    "jj = 0\n",
    "kk = 0\n",
    "# Inicializamos el error \n",
    "err_p = 999\n",
    "for i in opt:\n",
    "    for j in f_activation:\n",
    "        for k in init:\n",
    "            model_1_1 = modelo_1(i, j, k)\n",
    "            string_model = opt_s[ii] +'_'+ f_activation[jj] +'_'+ init_s[kk]+'_'\n",
    "            print(string_model)\n",
    "            if ii == 0 and jj == 0 and kk == 0:\n",
    "                param = string_model\n",
    "                id_r = 3\n",
    "            print(err_p)\n",
    "            flg, id_r_metodo, err_p_metodo = modelo_1_fit(model_1_1, string_model, err_p)\n",
    "            print(err_p_metodo)\n",
    "            if flg == 1:\n",
    "                param = string_model\n",
    "                id_r = id_r_metodo\n",
    "            err_p = err_p_metodo\n",
    "            kk = kk + 1\n",
    "        kk = 0\n",
    "        jj = jj + 1\n",
    "    jj = 0\n",
    "    ii = ii + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmsprop_selu_initNorm_\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(param)\n",
    "print(id_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "lstm_67 (LSTM)               (None, 200, 32)           20608     \n",
      "_________________________________________________________________\n",
      "lstm_68 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,588,961\n",
      "Trainable params: 2,588,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN LSTM\n",
    "model_rnn = load_model('RNN_'+param+'part='+str(id_r)+'.h5')                \n",
    "#model_rnn = load_model('RNN_'+'rmsprop_selu_initHe_'+'part='+'2'+'.h5') \n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11372  1128]\n",
      " [ 1550 10950]]\n",
      "Exactitud:  0.89288\n"
     ]
    }
   ],
   "source": [
    "Y_predt = model_rnn.predict(x_train)\n",
    "Y_predst = (Y_predt > 0.5)\n",
    "\n",
    "print(confusion_matrix(y_train, Y_predst))\n",
    "print(\"Exactitud: \", model_rnn.evaluate(x=x_train, y=y_train, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10996  1504]\n",
      " [ 2310 10190]]\n",
      "Exactitud:  0.84744\n"
     ]
    }
   ],
   "source": [
    "Y_predv = model_rnn.predict(x_val)\n",
    "Y_predsv = (Y_predv > 0.5)\n",
    "\n",
    "print(confusion_matrix(y_val, Y_predsv))\n",
    "print(\"Exactitud: \", model_rnn.evaluate(x=x_val, y=y_val, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En total se evaluó el desempeño de 36 combinaciones de parámetros bajo la arquitectura definida, logrando los resultados anteriores.\n",
    "Evaluamos la perdida de cada combinación en los datos de prueba:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Bajo desempeño identificado usando una función de activación **relu**. Solución sin convergencia utilizando **adam** y **rsmprop**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> El mejor desempeño usando el algoritmo de optimización **sgd** se logra con una función de activación **selu** e inicialización con **He**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Seguidamente se identifica un mejor el desempeño usando el algoritmo de optimización **adam** y utilizando una función de activación **sigmoide**, finalmente el mejor desempeño logrado con **Adam** es usando la función de activación **tanh** e inicialización con **He**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Finalmente, el mejor desempeño logrado se obtiene usando el algoritmo de optimización **rmsprop**, función de activación **selu** e inicialización **Normal**.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como resultado, se logra exactitud de **89.28%** y **84.74%** sobre datos de entrenamiento y prueba respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En este orden, a la configuración de red con mejor desempeño incrementamos el numero de unidades a **128** sobre la primera capa recurrente, **64** unidades a la siguiente capa y adicionamos una función Dropout con tasa de aprendizaje **0.2** antes de la capa de salida. Y entrenamos la red incrementando a 5 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_1 = Sequential()\n",
    "model_1_1.add(layers.Embedding(max_features, 128, input_length=maxlen))\n",
    "model_1_1.add(layers.LSTM(128, activation='selu', kernel_initializer=initNorm, return_sequences=True))\n",
    "model_1_1.add(layers.LSTM(64))\n",
    "model_1_1.add(Dropout(rate=0.2, seed=1))  \n",
    "model_1_1.add(layers.Dense(1, activation='sigmoid'))\n",
    "model_1_1.compile(loss='binary_crossentropy', optimizer=rmsprop, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_40 (Embedding)     (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "lstm_80 (LSTM)               (None, 200, 128)          131584    \n",
      "_________________________________________________________________\n",
      "lstm_81 (LSTM)               (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,741,057\n",
      "Trainable params: 2,741,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/5\n",
      "12500/12500 [==============================] - 1051s 84ms/step - loss: 0.5333 - acc: 0.7294 - val_loss: 0.4956 - val_acc: 0.7840\n",
      "Epoch 2/5\n",
      "12500/12500 [==============================] - 1039s 83ms/step - loss: 0.3187 - acc: 0.8748 - val_loss: 0.5235 - val_acc: 0.7935\n",
      "Epoch 3/5\n",
      "12500/12500 [==============================] - 1027s 82ms/step - loss: 0.2414 - acc: 0.9119 - val_loss: 0.3669 - val_acc: 0.8675\n",
      "Epoch 4/5\n",
      "12500/12500 [==============================] - 1018s 81ms/step - loss: 0.1746 - acc: 0.9394 - val_loss: 0.5278 - val_acc: 0.8241\n",
      "Epoch 5/5\n",
      "12500/12500 [==============================] - 1014s 81ms/step - loss: nan - acc: 0.0042 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/5\n",
      "12500/12500 [==============================] - 1163s 93ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "12500/12500 [==============================] - 1155s 92ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "12500/12500 [==============================] - 1008s 81ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "12500/12500 [==============================] - 995s 80ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "12500/12500 [==============================] - 1004s 80ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/5\n",
      "12500/12500 [==============================] - 1054s 84ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "12500/12500 [==============================] - 990s 79ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "12500/12500 [==============================] - 971s 78ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "12500/12500 [==============================] - 954s 76ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "12500/12500 [==============================] - 947s 76ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Desempeño (exactitud): accu_v1=0.0 , accu_v2=0.0\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "|  0.0   |  0.0   |  0.0   |\n",
      "+--------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Inicializamos la tabla donde guardamos los resultados\n",
    "x = PrettyTable([\"Exac_E\", \"Exac_V\", \"Exac_P\"])\n",
    "\n",
    "# Definimos el número máximo de iteraciones (épocas de la red)\n",
    "epocas=5\n",
    "\n",
    "# Inicializamos el error \n",
    "err_p = 999\n",
    "\n",
    "for i in range(0,3,1):\n",
    "    r = i^3\n",
    "    CE_x, CV_x, CE_y, CV_y = train_test_split(x_train, y_train, test_size = 0.5, random_state = r)\n",
    "             \n",
    "    # Ajustamos el modelo\n",
    "    history=model_1_1.fit(x=CE_x, y=CE_y, epochs=epocas, validation_data=(CV_x, CV_y), verbose=1, shuffle=False)\n",
    "      \n",
    "    # Calculamos las metricas\n",
    "    train_metrics = model_1_1.evaluate(x=CE_x, y=CE_y, verbose=0)\n",
    "    valid_metrics = model_1_1.evaluate(x=CV_x, y=CV_y, verbose=0)\n",
    "    test_metrics = model_1_1.evaluate(x=x_val, y=y_val, verbose=0)\n",
    "    \n",
    "    # Guardamos las métricas de desempeño\n",
    "    accu_e = train_metrics[1]\n",
    "    loss_e = train_metrics[0]\n",
    "    accu_v = valid_metrics[1]\n",
    "    loss_v = valid_metrics[0]\n",
    "    accu_p = test_metrics[1]\n",
    "    loss_p = test_metrics[0]\n",
    "    \n",
    "    if (loss_p < err_p):\n",
    "        pathr =('RNN_Reg_Drop_part='+str(r)+'.h5')\n",
    "        model_1_1.save(pathr) \n",
    "        err_p = loss_p\n",
    "    \n",
    "    # Imprimimos el desempeño para cada repetición\n",
    "    print('Desempeño (exactitud): accu_v1='+str(accu_v) +' , accu_v2='+str(accu_p))\n",
    "    \n",
    "    x.add_row([np.round(accu_e,4), np.round(accu_v,4), np.round(accu_p,4)])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resultados no favorables, algoritmo sin convergencia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.2\n",
    "\n",
    "Desarrolle otro modelo de red neuronal (de libre elección) para mejorar los resultados obtenidos con el mejor modelo obtenido hasta ahora.\n",
    "\n",
    "Puede explorar una red recurrente simple, LSTM, GRU, o cualquier otro tipo de red (CNN, CNN-LSTM, ...)\n",
    "\n",
    "Compare los resultados sobre los datos de prueba y analice el desempeño de su modelo. Concluya y proponga estrategias para seguir mejorando los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Con el objetivo de mejorar los resultados, exploramos el uso de una red recurrente GRU, con 64 unidades y utilizando como parámetros los identificados anteriormente con mejor desempeño: Algoritmo de optimización: rmsprop. Función de activación: selu e inicializador: Normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_43 (Embedding)     (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 200, 64)           37056     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,621,889\n",
      "Trainable params: 2,621,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1_2 = Sequential()\n",
    "model_1_2.add(layers.Embedding(max_features, 128, input_length=maxlen))\n",
    "model_1_2.add(layers.GRU(64, activation='selu', kernel_initializer=initNorm, return_sequences=True))\n",
    "model_1_2.add(layers.GRU(64))\n",
    "model_1_2.add(layers.Dense(1, activation='sigmoid'))\n",
    "model_1_2.compile(loss='binary_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
    "\n",
    "model_1_2.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 272s 22ms/step - loss: 0.4762 - acc: 0.7801 - val_loss: 0.3948 - val_acc: 0.8248\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 286s 23ms/step - loss: 0.2808 - acc: 0.8926 - val_loss: 0.7454 - val_acc: 0.7761\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 293s 23ms/step - loss: 0.2033 - acc: 0.9282 - val_loss: 0.3258 - val_acc: 0.8754\n",
      "Desempeño (exactitud): accu_v1=0.87544 , accu_v2=0.85688\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 295s 24ms/step - loss: 0.2314 - acc: 0.9106 - val_loss: 0.2390 - val_acc: 0.9110\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 299s 24ms/step - loss: 0.1534 - acc: 0.9455 - val_loss: 0.3342 - val_acc: 0.8915\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 298s 24ms/step - loss: 0.1062 - acc: 0.9638 - val_loss: 0.3737 - val_acc: 0.8920\n",
      "Desempeño (exactitud): accu_v1=0.8920000000190735 , accu_v2=0.85964\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 291s 23ms/step - loss: 0.1682 - acc: 0.9395 - val_loss: 0.1658 - val_acc: 0.9392\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 295s 24ms/step - loss: 0.1097 - acc: 0.9631 - val_loss: 0.2496 - val_acc: 0.9206\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 296s 24ms/step - loss: 0.0669 - acc: 0.9780 - val_loss: 0.2709 - val_acc: 0.9214\n",
      "Desempeño (exactitud): accu_v1=0.921359999961853 , accu_v2=0.8634\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.959  | 0.8754 | 0.8569 |\n",
      "| 0.9731 | 0.892  | 0.8596 |\n",
      "| 0.9872 | 0.9214 | 0.8634 |\n",
      "+--------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Inicializamos la tabla donde guardamos los resultados\n",
    "x = PrettyTable([\"Exac_E\", \"Exac_V\", \"Exac_P\"])\n",
    "\n",
    "# Definimos el número máximo de iteraciones (épocas de la red)\n",
    "epocas=3\n",
    "\n",
    "# Inicializamos el error \n",
    "err_p = 999\n",
    "\n",
    "for i in range(0,3,1):\n",
    "    r = i^3\n",
    "    CE_x, CV_x, CE_y, CV_y = train_test_split(x_train, y_train, test_size = 0.5, random_state = r)\n",
    "             \n",
    "    # Ajustamos el modelo\n",
    "    history=model_1_2.fit(x=CE_x, y=CE_y, epochs=epocas, validation_data=(CV_x, CV_y), verbose=1, shuffle=False)\n",
    "      \n",
    "    # Calculamos las metricas\n",
    "    train_metrics = model_1_2.evaluate(x=CE_x, y=CE_y, verbose=0)\n",
    "    valid_metrics = model_1_2.evaluate(x=CV_x, y=CV_y, verbose=0)\n",
    "    test_metrics = model_1_2.evaluate(x=x_val, y=y_val, verbose=0)\n",
    "    \n",
    "    # Guardamos las métricas de desempeño\n",
    "    accu_e = train_metrics[1]\n",
    "    loss_e = train_metrics[0]\n",
    "    accu_v = valid_metrics[1]\n",
    "    loss_v = valid_metrics[0]\n",
    "    accu_p = test_metrics[1]\n",
    "    loss_p = test_metrics[0]\n",
    "    \n",
    "    if (loss_p < err_p):\n",
    "        pathr =('RNN_GRU_part='+str(r)+'.h5')\n",
    "        model_1_2.save(pathr) \n",
    "        err_p = loss_p\n",
    "        id_r = r\n",
    "    \n",
    "    # Imprimimos el desempeño para cada repetición\n",
    "    print('Desempeño (exactitud): accu_v1='+str(accu_v) +' , accu_v2='+str(accu_p))\n",
    "    \n",
    "    x.add_row([np.round(accu_e,4), np.round(accu_v,4), np.round(accu_p,4)])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['acc'])  \n",
    "plt.plot(history.history['val_acc'])  \n",
    "plt.title('Exactitud')  \n",
    "plt.ylabel('Acc')  \n",
    "plt.xlabel('Epoca')  \n",
    "plt.legend(['Entreno', 'Validacion'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(1) \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('Pérdida')  \n",
    "plt.ylabel('Pérdida')  \n",
    "plt.xlabel('Epoca')  \n",
    "plt.legend(['Entreno', 'Validación'], loc='upper right')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_43 (Embedding)     (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 200, 64)           37056     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,621,889\n",
      "Trainable params: 2,621,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN GRU\n",
    "model_rnn_gru = load_model('RNN_GRU_part='+str(id_r)+'.h5')\n",
    "\n",
    "model_rnn_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11828   672]\n",
      " [ 1398 11102]]\n",
      "Exactitud:  0.9172\n"
     ]
    }
   ],
   "source": [
    "Y_predt = model_rnn_gru.predict(x_train)\n",
    "Y_predst = (Y_predt > 0.5)\n",
    "\n",
    "print(confusion_matrix(y_train, Y_predst))\n",
    "print(\"Exactitud: \", model_rnn_gru.evaluate(x=x_train, y=y_train, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11420  1080]\n",
      " [ 2498 10002]]\n",
      "Exactitud:  0.85688\n"
     ]
    }
   ],
   "source": [
    "Y_predv = model_rnn_gru.predict(x_val)\n",
    "Y_predsv = (Y_predv > 0.5)\n",
    "\n",
    "print(confusion_matrix(y_val, Y_predsv))\n",
    "print(\"Exactitud: \", model_rnn_gru.evaluate(x=x_val, y=y_val, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como resultado, logramos mejorar el desempeño anterior, se logra exactitud de **91.72%** y **85.68%** sobre datos de entrenamiento y prueba respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalmente, a la arquitectura de red anterior, modificamos las dos capas GRU adicionando una capa bidireccional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_44 (Embedding)     (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 200, 128)          74112     \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 128)               74112     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,708,353\n",
      "Trainable params: 2,708,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1_2 = Sequential()\n",
    "model_1_2.add(layers.Embedding(max_features, 128, input_length=maxlen))\n",
    "model_1_2.add(layers.Bidirectional(layers.GRU(64, activation='selu', kernel_initializer=initNorm, return_sequences=True)))\n",
    "model_1_2.add(layers.Bidirectional(layers.GRU(64)))\n",
    "model_1_2.add(layers.Dense(1, activation='sigmoid'))\n",
    "model_1_2.compile(loss='binary_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
    "\n",
    "model_1_2.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 629s 50ms/step - loss: 0.4627 - acc: 0.7786 - val_loss: 0.3384 - val_acc: 0.8573\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 591s 47ms/step - loss: 0.2712 - acc: 0.8959 - val_loss: 0.4464 - val_acc: 0.7844\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 603s 48ms/step - loss: 0.2107 - acc: 0.9193 - val_loss: 0.3009 - val_acc: 0.8746\n",
      "Desempeño (exactitud): accu_v1=0.874640000038147 , accu_v2=0.86372\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 619s 50ms/step - loss: 0.2368 - acc: 0.9074 - val_loss: 0.2532 - val_acc: 0.8962\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 621s 50ms/step - loss: 0.1665 - acc: 0.9367 - val_loss: 0.3348 - val_acc: 0.8743\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 620s 50ms/step - loss: 0.1214 - acc: 0.9581 - val_loss: 0.3652 - val_acc: 0.8872\n",
      "Desempeño (exactitud): accu_v1=0.8872 , accu_v2=0.85496\n",
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "12500/12500 [==============================] - 631s 50ms/step - loss: 0.1749 - acc: 0.9369 - val_loss: 0.1698 - val_acc: 0.9388\n",
      "Epoch 2/3\n",
      "12500/12500 [==============================] - 649s 52ms/step - loss: 0.1161 - acc: 0.9602 - val_loss: 0.2150 - val_acc: 0.9266\n",
      "Epoch 3/3\n",
      "12500/12500 [==============================] - 635s 51ms/step - loss: 0.0792 - acc: 0.9744 - val_loss: 0.2412 - val_acc: 0.9217\n",
      "Desempeño (exactitud): accu_v1=0.92168 , accu_v2=0.85968\n",
      "+--------+--------+--------+\n",
      "| Exac_E | Exac_V | Exac_P |\n",
      "+--------+--------+--------+\n",
      "| 0.9517 | 0.8746 | 0.8637 |\n",
      "| 0.9677 | 0.8872 | 0.855  |\n",
      "| 0.9865 | 0.9217 | 0.8597 |\n",
      "+--------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Inicializamos la tabla donde guardamos los resultados\n",
    "x = PrettyTable([\"Exac_E\", \"Exac_V\", \"Exac_P\"])\n",
    "\n",
    "# Definimos el número máximo de iteraciones (épocas de la red)\n",
    "epocas=3\n",
    "\n",
    "# Inicializamos el error \n",
    "err_p = 999\n",
    "\n",
    "for i in range(0,3,1):\n",
    "    r = i^3\n",
    "    CE_x, CV_x, CE_y, CV_y = train_test_split(x_train, y_train, test_size = 0.5, random_state = r)\n",
    "             \n",
    "    # Ajustamos el modelo\n",
    "    history=model_1_2.fit(x=CE_x, y=CE_y, epochs=epocas, validation_data=(CV_x, CV_y), verbose=1, shuffle=False)\n",
    "      \n",
    "    # Calculamos las metricas\n",
    "    train_metrics = model_1_2.evaluate(x=CE_x, y=CE_y, verbose=0)\n",
    "    valid_metrics = model_1_2.evaluate(x=CV_x, y=CV_y, verbose=0)\n",
    "    test_metrics = model_1_2.evaluate(x=x_val, y=y_val, verbose=0)\n",
    "    \n",
    "    # Guardamos las métricas de desempeño\n",
    "    accu_e = train_metrics[1]\n",
    "    loss_e = train_metrics[0]\n",
    "    accu_v = valid_metrics[1]\n",
    "    loss_v = valid_metrics[0]\n",
    "    accu_p = test_metrics[1]\n",
    "    loss_p = test_metrics[0]\n",
    "    \n",
    "    if (loss_p < err_p):\n",
    "        pathr =('BRNN_GRU_part='+str(r)+'.h5')\n",
    "        model_1_2.save(pathr) \n",
    "        err_p = loss_p\n",
    "        id_r = r\n",
    "    \n",
    "    # Imprimimos el desempeño para cada repetición\n",
    "    print('Desempeño (exactitud): accu_v1='+str(accu_v) +' , accu_v2='+str(accu_p))\n",
    "    \n",
    "    x.add_row([np.round(accu_e,4), np.round(accu_v,4), np.round(accu_p,4)])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['acc'])  \n",
    "plt.plot(history.history['val_acc'])  \n",
    "plt.title('Exactitud')  \n",
    "plt.ylabel('Acc')  \n",
    "plt.xlabel('Epoca')  \n",
    "plt.legend(['Entreno', 'Validacion'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(1) \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('Pérdida')  \n",
    "plt.ylabel('Pérdida')  \n",
    "plt.xlabel('Epoca')  \n",
    "plt.legend(['Entreno', 'Validación'], loc='upper right')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_44 (Embedding)     (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 200, 128)          74112     \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 128)               74112     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,708,353\n",
      "Trainable params: 2,708,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# BRNN GRU\n",
    "model_brnn_gru = load_model('BRNN_GRU_part='+str(id_r)+'.h5')\n",
    "\n",
    "model_brnn_gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10947  1553]\n",
      " [  618 11882]]\n",
      "Exactitud:  0.91316\n"
     ]
    }
   ],
   "source": [
    "Y_predt = model_brnn_gru.predict(x_train)\n",
    "Y_predst = (Y_predt > 0.5)\n",
    "\n",
    "print(confusion_matrix(y_train, Y_predst))\n",
    "print(\"Exactitud: \", model_brnn_gru.evaluate(x=x_train, y=y_train, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10160  2340]\n",
      " [ 1067 11433]]\n",
      "Exactitud:  0.86372\n"
     ]
    }
   ],
   "source": [
    "Y_predv = model_brnn_gru.predict(x_val)\n",
    "Y_predsv = (Y_predv > 0.5)\n",
    "\n",
    "print(confusion_matrix(y_val, Y_predsv))\n",
    "print(\"Exactitud: \", model_brnn_gru.evaluate(x=x_val, y=y_val, verbose=0)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Excelente resultado, logramos mejorar nuevamente el desempeño anterior, se logra exactitud de **91.31%** y **86.37%** sobre datos de entrenamiento y prueba respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalmente, como recomendaciones siguientes, probaríamos modificando la arquitectura de la red adicionando algunas capas bidireccionales GRU, modificando diferente cantidad de unidades en cada capa. "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "wRuwL",
   "launcher_item_id": "NI888"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
